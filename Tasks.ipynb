{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c34f0d11e0814cc99684ed57f0fe5387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e94894858ace42eca3cfbf5e2b30dd52",
              "IPY_MODEL_a4565efb4cf54583b9cf867b43f8483e",
              "IPY_MODEL_05986d0b9a104fa0812861f46b805cf6"
            ],
            "layout": "IPY_MODEL_d5a5d71c6be64476b0b407b6c0859ec6"
          }
        },
        "e94894858ace42eca3cfbf5e2b30dd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d03fdc1ccb14da4aa2443feb2fc2888",
            "placeholder": "​",
            "style": "IPY_MODEL_2d7b423d00d240e19a094bdad5203b84",
            "value": "Batches: 100%"
          }
        },
        "a4565efb4cf54583b9cf867b43f8483e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f81a3ddd3d1d40b2b09ba4da7360abd9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c576dec5c89c449fbbc22d4466d9f729",
            "value": 2
          }
        },
        "05986d0b9a104fa0812861f46b805cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ff1a46164d43fbb258db61ba6e3098",
            "placeholder": "​",
            "style": "IPY_MODEL_20cadb228a2e4db892054739d57fc1a5",
            "value": " 2/2 [00:00&lt;00:00,  6.33it/s]"
          }
        },
        "d5a5d71c6be64476b0b407b6c0859ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d03fdc1ccb14da4aa2443feb2fc2888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d7b423d00d240e19a094bdad5203b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f81a3ddd3d1d40b2b09ba4da7360abd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c576dec5c89c449fbbc22d4466d9f729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81ff1a46164d43fbb258db61ba6e3098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20cadb228a2e4db892054739d57fc1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17c51a675d7844d684c9c723998d3814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82f4c4504a35437e9b09bef32a0e6759",
              "IPY_MODEL_96e3c5be5ad7402f8a0a50150787f702",
              "IPY_MODEL_a6ca3c0bc7674a789484741b83bf9d44"
            ],
            "layout": "IPY_MODEL_77541d7ceb0d4b37bcd1e6597c5e11d5"
          }
        },
        "82f4c4504a35437e9b09bef32a0e6759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8f3f0a3c405422c9d17f209286762fc",
            "placeholder": "​",
            "style": "IPY_MODEL_b761c71cd4164192892012ec9ad9f1fd",
            "value": "Batches: 100%"
          }
        },
        "96e3c5be5ad7402f8a0a50150787f702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bac09121502434dbd7cd55b36966fba",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_306431d2a46b4a68aeff67841592e0cb",
            "value": 16
          }
        },
        "a6ca3c0bc7674a789484741b83bf9d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29f0fad8abc049b1a95ded56320ecc6d",
            "placeholder": "​",
            "style": "IPY_MODEL_b85fc1486ba743f4acbeb64fe8267857",
            "value": " 16/16 [00:00&lt;00:00, 24.40it/s]"
          }
        },
        "77541d7ceb0d4b37bcd1e6597c5e11d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f3f0a3c405422c9d17f209286762fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b761c71cd4164192892012ec9ad9f1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bac09121502434dbd7cd55b36966fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "306431d2a46b4a68aeff67841592e0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29f0fad8abc049b1a95ded56320ecc6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85fc1486ba743f4acbeb64fe8267857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aea57143ad543c1b92cd5a12018e970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8f6480e4e4f417c8ae4eab8ae558aad",
              "IPY_MODEL_b4ee2a613a0b42ddb8d661cb9b15ed7c",
              "IPY_MODEL_8e82dabea0a4494b8f3271e5312f1542"
            ],
            "layout": "IPY_MODEL_c9c513b561424ddaa9b9cc2212a07684"
          }
        },
        "e8f6480e4e4f417c8ae4eab8ae558aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62a8c3529e8d4bb4a0d4b62ef1c2e6b0",
            "placeholder": "​",
            "style": "IPY_MODEL_99acadb6350f46c48ff6ff53ee0b9f97",
            "value": "Batches: 100%"
          }
        },
        "b4ee2a613a0b42ddb8d661cb9b15ed7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5fc5a55c4c24ab4a7330cd9c9b231e0",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fe78060b2a94e348dbf17efc9aee665",
            "value": 32
          }
        },
        "8e82dabea0a4494b8f3271e5312f1542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84f1111aeab241bc8d82d3339d694c45",
            "placeholder": "​",
            "style": "IPY_MODEL_e00d890bf7c04c58b805f4f3dd4f5aa6",
            "value": " 32/32 [00:01&lt;00:00, 29.53it/s]"
          }
        },
        "c9c513b561424ddaa9b9cc2212a07684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a8c3529e8d4bb4a0d4b62ef1c2e6b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99acadb6350f46c48ff6ff53ee0b9f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5fc5a55c4c24ab4a7330cd9c9b231e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe78060b2a94e348dbf17efc9aee665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84f1111aeab241bc8d82d3339d694c45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00d890bf7c04c58b805f4f3dd4f5aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5459464a0a974c859258d44de9079a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5442452beb7411e8329e89bfc9abef0",
              "IPY_MODEL_ff1587db3fc24378aadc06da9ce77b20",
              "IPY_MODEL_435383f86c22453f840917af37597c88"
            ],
            "layout": "IPY_MODEL_c104d25b76104e28b2b3801bda3d3cd6"
          }
        },
        "b5442452beb7411e8329e89bfc9abef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efd36bfc8c9b40a0bca7c6dee937e9d3",
            "placeholder": "​",
            "style": "IPY_MODEL_45e40783b4b04875bb6bee6935a4c0e5",
            "value": "Batches: 100%"
          }
        },
        "ff1587db3fc24378aadc06da9ce77b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d9b1f75d124f25ad635363860bdfb6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3228efb5ff0b48b1b25c0b0040e375d6",
            "value": 1
          }
        },
        "435383f86c22453f840917af37597c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06156530bd4546dda4fbdee8d6cd6106",
            "placeholder": "​",
            "style": "IPY_MODEL_15154ed4c81b412e83acb45631337fc0",
            "value": " 1/1 [00:00&lt;00:00, 31.34it/s]"
          }
        },
        "c104d25b76104e28b2b3801bda3d3cd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd36bfc8c9b40a0bca7c6dee937e9d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e40783b4b04875bb6bee6935a4c0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76d9b1f75d124f25ad635363860bdfb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3228efb5ff0b48b1b25c0b0040e375d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06156530bd4546dda4fbdee8d6cd6106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15154ed4c81b412e83acb45631337fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7881cf4b44c44cfb3df0047f92d9a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_952a600298a243f8933b3d3b609b8a92",
              "IPY_MODEL_afc8f92588134899bdad606aee43594c",
              "IPY_MODEL_ee019990b3654052a22cfe229f4489ed"
            ],
            "layout": "IPY_MODEL_f2f73aec56274eeca8ec6e187140120e"
          }
        },
        "952a600298a243f8933b3d3b609b8a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48a844831564447dae0acfd741a603ea",
            "placeholder": "​",
            "style": "IPY_MODEL_15dc50fe94f9495492a386d2e056c718",
            "value": "Batches: 100%"
          }
        },
        "afc8f92588134899bdad606aee43594c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bbdc276e1604b8b8d1390a4e00b8277",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5c8b8df22ee4b2a929a3a88aae1280d",
            "value": 1
          }
        },
        "ee019990b3654052a22cfe229f4489ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b178b315f6de49ffba88205073bcfba9",
            "placeholder": "​",
            "style": "IPY_MODEL_70221919e51b434fbcc0f9d49be59f3b",
            "value": " 1/1 [00:00&lt;00:00, 28.35it/s]"
          }
        },
        "f2f73aec56274eeca8ec6e187140120e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a844831564447dae0acfd741a603ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15dc50fe94f9495492a386d2e056c718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bbdc276e1604b8b8d1390a4e00b8277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c8b8df22ee4b2a929a3a88aae1280d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b178b315f6de49ffba88205073bcfba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70221919e51b434fbcc0f9d49be59f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e33bf3eac6447b2a0a80c5abe390114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77b7d137a410438cae295776f2ae82ab",
              "IPY_MODEL_a64d3913be174f3486a3c2bd459021ba",
              "IPY_MODEL_9e17ea24338147a096144e9a298bc081"
            ],
            "layout": "IPY_MODEL_757425e6d97c4aca8161e706d19b8015"
          }
        },
        "77b7d137a410438cae295776f2ae82ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f7879af54d4471b83e4f103bd38e80f",
            "placeholder": "​",
            "style": "IPY_MODEL_116b9717fc774fb79d11187f482bc9dc",
            "value": "Batches: 100%"
          }
        },
        "a64d3913be174f3486a3c2bd459021ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f4112f21c442a89298b7be1f01015e",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f828a0f3e694300a13d04bfd6858e19",
            "value": 32
          }
        },
        "9e17ea24338147a096144e9a298bc081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a45f0d1c83463a83eaefa9e1ccf9d0",
            "placeholder": "​",
            "style": "IPY_MODEL_5f2ed9ab5ace46e8998fdebfab0d3387",
            "value": " 32/32 [00:01&lt;00:00, 32.28it/s]"
          }
        },
        "757425e6d97c4aca8161e706d19b8015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f7879af54d4471b83e4f103bd38e80f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "116b9717fc774fb79d11187f482bc9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94f4112f21c442a89298b7be1f01015e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f828a0f3e694300a13d04bfd6858e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9a45f0d1c83463a83eaefa9e1ccf9d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2ed9ab5ace46e8998fdebfab0d3387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc1bc3cdb66e431091d1521ada59e2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c904a52b4b34878ad63d133bdb2f3c0",
              "IPY_MODEL_16be3f9c467a4e89a1427326c5cb89e8",
              "IPY_MODEL_36c5ff69baa64049b6e473514b67d556"
            ],
            "layout": "IPY_MODEL_6fae5f0e42b843b1a4277e506fc3c346"
          }
        },
        "3c904a52b4b34878ad63d133bdb2f3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ed91f05c2f4171b35513921f0d9813",
            "placeholder": "​",
            "style": "IPY_MODEL_769b385d0b3d4b18b09b538bea1ead94",
            "value": "Batches: 100%"
          }
        },
        "16be3f9c467a4e89a1427326c5cb89e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ceb263c3541430187d1d4329eae72b8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55674d74657740fa9e766c7c85ad134a",
            "value": 1
          }
        },
        "36c5ff69baa64049b6e473514b67d556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d155ea69f5a47acad7b9c45043f5b4d",
            "placeholder": "​",
            "style": "IPY_MODEL_db0004db50044b75a256cf225fef155f",
            "value": " 1/1 [00:00&lt;00:00, 34.68it/s]"
          }
        },
        "6fae5f0e42b843b1a4277e506fc3c346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ed91f05c2f4171b35513921f0d9813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "769b385d0b3d4b18b09b538bea1ead94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ceb263c3541430187d1d4329eae72b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55674d74657740fa9e766c7c85ad134a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d155ea69f5a47acad7b9c45043f5b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db0004db50044b75a256cf225fef155f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c10d0670eea47ba8228b0bdfe70a9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beef6bcbf5a448cc9d43228a27393112",
              "IPY_MODEL_bc3ccfb4d0e9430baa98303f27ffb7a0",
              "IPY_MODEL_6b4c8f9a5aa44f77a5b49e778c3428e4"
            ],
            "layout": "IPY_MODEL_b22fb999ca4d4df1bb315341850ed99b"
          }
        },
        "beef6bcbf5a448cc9d43228a27393112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edb0859123c483d9f9bcfbaf29a7284",
            "placeholder": "​",
            "style": "IPY_MODEL_4129285b60ad4c329f7544e5dedd80ec",
            "value": "Batches: 100%"
          }
        },
        "bc3ccfb4d0e9430baa98303f27ffb7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95a035e04bc3499c9d3abb8b44bd90d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_967b2e28e8fa4e6f8757773584d62391",
            "value": 1
          }
        },
        "6b4c8f9a5aa44f77a5b49e778c3428e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c21447ba4f5492398788d265d005b15",
            "placeholder": "​",
            "style": "IPY_MODEL_4730574ad7f14c2889cd286ccca432f7",
            "value": " 1/1 [00:00&lt;00:00, 32.50it/s]"
          }
        },
        "b22fb999ca4d4df1bb315341850ed99b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edb0859123c483d9f9bcfbaf29a7284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4129285b60ad4c329f7544e5dedd80ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95a035e04bc3499c9d3abb8b44bd90d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967b2e28e8fa4e6f8757773584d62391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c21447ba4f5492398788d265d005b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4730574ad7f14c2889cd286ccca432f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Kautilya ML Challenge Implementation\n",
        "\n",
        "This notebook implements both tasks of the Kautilya ML Challenge:\n",
        "1. Semantic Search on Twitter API Documentation\n",
        "2. Narrative Building from News Dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OqFAkvkwTbNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUW_MdWITYUa",
        "outputId": "a636e815-5c44-4e58-b3bd-901985498388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dependencies installed successfully\n"
          ]
        }
      ],
      "source": [
        "# Install all required libraries\n",
        "# This may take 2-3 minutes to complete\n",
        "\n",
        "!pip install -q sentence-transformers faiss-cpu transformers torch\n",
        "!pip install -q scikit-learn pandas numpy ijson requests\n",
        "!pip install -q accelerate sentencepiece\n",
        "\n",
        "print(\"All dependencies installed successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Required Libraries\n",
        "\n",
        "Setting up all necessary imports and configuring the environment for optimal performance.\n"
      ],
      "metadata": {
        "id": "OpZ_NdmaTsSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import os\n",
        "import argparse\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data processing imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple, Any\n",
        "\n",
        "# Machine learning imports\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Deep learning imports\n",
        "import torch\n",
        "\n",
        "# Check TPU availability and configure device\n",
        "try:\n",
        "    import torch_xla\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    device = xm.xla_device()\n",
        "    print(f\"TPU detected and configured: {device}\")\n",
        "except:\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(\"Setup complete\")\n"
      ],
      "metadata": {
        "id": "hWxkcerkTqFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb62e102-7ac7-4f88-c928-a6af15edb1bd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "PyTorch version: 2.8.0+cu126\n",
            "Setup complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Semantic Search Setup\n",
        "\n",
        "First, we need to clone the Twitter(Now it is X) API Postman documentation repository and prepare the data for semantic search.\n"
      ],
      "metadata": {
        "id": "7hzUKrCLTzxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the Twitter API Postman documentation repository\n",
        "# This contains the complete Twitter API documentation in Postman collection format\n",
        "\n",
        "!git clone https://github.com/xdevplatform/postman-twitter-api.git\n",
        "\n",
        "# Verify the clone was successful\n",
        "if os.path.exists('postman-twitter-api'):\n",
        "    print(\"Repository cloned successfully\")\n",
        "\n",
        "    # List the contents to understand the structure\n",
        "    print(\"\\nRepository contents:\")\n",
        "    !ls -la postman-twitter-api/\n",
        "else:\n",
        "    print(\"Error: Repository not found\")\n"
      ],
      "metadata": {
        "id": "gEyJi0irTxh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dda8e34-9c2c-496a-8ab0-7e3f7816820f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'postman-twitter-api' already exists and is not an empty directory.\n",
            "Repository cloned successfully\n",
            "\n",
            "Repository contents:\n",
            "total 968\n",
            "drwxr-xr-x 4 root root   4096 Nov 17 09:11  .\n",
            "drwxr-xr-x 1 root root   4096 Nov 17 09:18  ..\n",
            "-rw-r--r-- 1 root root   5751 Nov 17 09:11  CODE_OF_CONDUCT.md\n",
            "-rw-r--r-- 1 root root    804 Nov 17 09:11  CONTRIBUTING.md\n",
            "drwxr-xr-x 8 root root   4096 Nov 17 09:11  .git\n",
            "drwxr-xr-x 2 root root   4096 Nov 17 09:11  .github\n",
            "-rw-r--r-- 1 root root  11341 Nov 17 09:11  LICENSE\n",
            "-rw-r--r-- 1 root root   1117 Nov 17 09:11  README.md\n",
            "-rw-r--r-- 1 root root 938349 Nov 17 09:11 'Twitter API v2.postman_collection.json'\n",
            "-rw-r--r-- 1 root root    660 Nov 17 09:11 'Twitter API v2.postman_environment.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse Twitter API Documentation\n",
        "\n",
        "Extract all API endpoints, descriptions, and parameters from the Postman collection files.\n"
      ],
      "metadata": {
        "id": "JtkxbPp4UNgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse Postman collection and extract documentation chunks\n",
        "def parse_postman_collection(collection_path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Parse Postman collection JSON and extract API documentation chunks.\n",
        "    Each chunk contains endpoint information that will be searchable.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "\n",
        "    try:\n",
        "        with open(collection_path, 'r', encoding='utf-8') as f:\n",
        "            collection = json.load(f)\n",
        "\n",
        "        # Recursive function to process items in the collection\n",
        "        def process_item(item, parent_name=\"\"):\n",
        "            \"\"\"\n",
        "            Recursively process each item in the Postman collection.\n",
        "            Items can be nested, so we traverse the entire tree.\n",
        "            \"\"\"\n",
        "            if 'item' in item:\n",
        "                # This is a folder containing more items\n",
        "                folder_name = item.get('name', '')\n",
        "                for sub_item in item['item']:\n",
        "                    process_item(sub_item, folder_name)\n",
        "            else:\n",
        "                # This is an actual API request\n",
        "                request = item.get('request', {})\n",
        "\n",
        "                # Extract all relevant information\n",
        "                name = item.get('name', 'Unnamed')\n",
        "                description = item.get('description', '')\n",
        "\n",
        "                # Get HTTP method\n",
        "                method = request.get('method', 'GET')\n",
        "\n",
        "                # Get URL information\n",
        "                url_info = request.get('url', {})\n",
        "                if isinstance(url_info, str):\n",
        "                    url = url_info\n",
        "                else:\n",
        "                    url = url_info.get('raw', '')\n",
        "\n",
        "                # Get query parameters\n",
        "                query_params = []\n",
        "                if isinstance(url_info, dict) and 'query' in url_info:\n",
        "                    for param in url_info.get('query', []):\n",
        "                        param_name = param.get('key', '')\n",
        "                        param_desc = param.get('description', '')\n",
        "                        query_params.append(f\"{param_name}: {param_desc}\")\n",
        "\n",
        "                # Get request body information\n",
        "                body_info = \"\"\n",
        "                if 'body' in request:\n",
        "                    body = request['body']\n",
        "                    if 'raw' in body:\n",
        "                        body_info = body.get('description', '')\n",
        "\n",
        "                # Combine all information into a searchable text chunk\n",
        "                chunk_text = f\"API: {name}\\n\"\n",
        "                chunk_text += f\"Method: {method}\\n\"\n",
        "                chunk_text += f\"Endpoint: {url}\\n\"\n",
        "                if parent_name:\n",
        "                    chunk_text += f\"Category: {parent_name}\\n\"\n",
        "                if description:\n",
        "                    chunk_text += f\"Description: {description}\\n\"\n",
        "                if query_params:\n",
        "                    chunk_text += f\"Parameters: {', '.join(query_params)}\\n\"\n",
        "                if body_info:\n",
        "                    chunk_text += f\"Body: {body_info}\\n\"\n",
        "\n",
        "                # Create chunk dictionary\n",
        "                chunk = {\n",
        "                    'text': chunk_text,\n",
        "                    'name': name,\n",
        "                    'method': method,\n",
        "                    'url': url,\n",
        "                    'category': parent_name,\n",
        "                    'description': description\n",
        "                }\n",
        "\n",
        "                chunks.append(chunk)\n",
        "\n",
        "        # Start processing from the root\n",
        "        if 'item' in collection:\n",
        "            for item in collection['item']:\n",
        "                process_item(item)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing collection: {e}\")\n",
        "        return []\n",
        "\n",
        "# Find and parse all Postman collection files\n",
        "collection_files = []\n",
        "for root, dirs, files in os.walk('postman-twitter-api'):\n",
        "    for file in files:\n",
        "        if file.endswith('.json') and 'collection' in file.lower():\n",
        "            collection_files.append(os.path.join(root, file))\n",
        "\n",
        "print(f\"Found {len(collection_files)} collection files\")\n",
        "\n",
        "# Parse all collections\n",
        "all_chunks = []\n",
        "for collection_file in collection_files:\n",
        "    print(f\"Parsing: {collection_file}\")\n",
        "    chunks = parse_postman_collection(collection_file)\n",
        "    all_chunks.extend(chunks)\n",
        "    print(f\"  Extracted {len(chunks)} API endpoints\")\n",
        "\n",
        "print(f\"\\nTotal API endpoints extracted: {len(all_chunks)}\")\n",
        "\n",
        "# Display a sample chunk\n",
        "if all_chunks:\n",
        "    print(\"\\nSample chunk:\")\n",
        "    print(all_chunks[0]['text'][:300])\n"
      ],
      "metadata": {
        "id": "881wdMkQUMQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746693e7-ea11-4eff-d4b4-42e97c9faab1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 collection files\n",
            "Parsing: postman-twitter-api/Twitter API v2.postman_collection.json\n",
            "  Extracted 56 API endpoints\n",
            "\n",
            "Total API endpoints extracted: 56\n",
            "\n",
            "Sample chunk:\n",
            "API: Single Tweet\n",
            "Method: GET\n",
            "Endpoint: https://api.twitter.com/2/tweets/:id\n",
            "Category: Tweet Lookup\n",
            "Parameters: tweet.fields: Comma-separated list of fields for the Tweet object.\n",
            "\n",
            "Allowed values:\n",
            "attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Semantic Search Index\n",
        "\n",
        "Initialize the sentence transformer model and create embeddings for all documentation chunks. We use FAISS for efficient similarity search.\n"
      ],
      "metadata": {
        "id": "aphX_XDeUiu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the sentence transformer model\n",
        "# Using all-MiniLM-L6-v2 for balance between speed and quality\n",
        "print(\"Loading sentence transformer model...\")\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Move model to appropriate device\n",
        "if 'xla' not in str(device):\n",
        "    model = model.to(device)\n",
        "\n",
        "print(f\"Model loaded on {device}\")\n",
        "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
        "\n",
        "# Generate embeddings for all documentation chunks\n",
        "print(\"\\nGenerating embeddings for all documentation chunks...\")\n",
        "chunk_texts = [chunk['text'] for chunk in all_chunks]\n",
        "\n",
        "# Batch encoding for efficiency\n",
        "batch_size = 32\n",
        "embeddings = model.encode(\n",
        "    chunk_texts,\n",
        "    batch_size=batch_size,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "print(f\"Generated {len(embeddings)} embeddings\")\n",
        "print(f\"Embedding shape: {embeddings.shape}\")\n",
        "\n",
        "# Normalize embeddings for cosine similarity\n",
        "embeddings_normalized = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "# Build FAISS index for fast similarity search\n",
        "print(\"\\nBuilding FAISS index...\")\n",
        "dimension = embeddings_normalized.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "# Add all embeddings to the index\n",
        "index.add(embeddings_normalized.astype('float32'))\n",
        "\n",
        "print(f\"FAISS index built with {index.ntotal} vectors\")\n",
        "print(\"Semantic search system ready\")\n"
      ],
      "metadata": {
        "id": "JhevNCtEUgyB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "c34f0d11e0814cc99684ed57f0fe5387",
            "e94894858ace42eca3cfbf5e2b30dd52",
            "a4565efb4cf54583b9cf867b43f8483e",
            "05986d0b9a104fa0812861f46b805cf6",
            "d5a5d71c6be64476b0b407b6c0859ec6",
            "7d03fdc1ccb14da4aa2443feb2fc2888",
            "2d7b423d00d240e19a094bdad5203b84",
            "f81a3ddd3d1d40b2b09ba4da7360abd9",
            "c576dec5c89c449fbbc22d4466d9f729",
            "81ff1a46164d43fbb258db61ba6e3098",
            "20cadb228a2e4db892054739d57fc1a5"
          ]
        },
        "outputId": "0a807a26-0914-401c-e069-716b4ce1bef6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sentence transformer model...\n",
            "Model loaded on cuda\n",
            "Embedding dimension: 384\n",
            "\n",
            "Generating embeddings for all documentation chunks...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c34f0d11e0814cc99684ed57f0fe5387"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 56 embeddings\n",
            "Embedding shape: (56, 384)\n",
            "\n",
            "Building FAISS index...\n",
            "FAISS index built with 56 vectors\n",
            "Semantic search system ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic Search Implementation\n",
        "\n",
        "Function to perform semantic search over the Twitter API documentation.\n"
      ],
      "metadata": {
        "id": "WPpJkt-xVDcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Perform semantic search over Twitter API documentation.\n",
        "\n",
        "    Parameters:\n",
        "    query: The search query string\n",
        "    k: Number of top results to return\n",
        "\n",
        "    Returns:\n",
        "    List of dictionaries containing search results with relevance scores\n",
        "    \"\"\"\n",
        "    # Encode the query\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
        "\n",
        "    # Search the index\n",
        "    scores, indices = index.search(query_embedding.astype('float32'), k)\n",
        "\n",
        "    # Prepare results\n",
        "    results = []\n",
        "    for idx, score in zip(indices[0], scores[0]):\n",
        "        chunk = all_chunks[idx]\n",
        "        result = {\n",
        "            'rank': len(results) + 1,\n",
        "            'score': float(score),\n",
        "            'name': chunk['name'],\n",
        "            'method': chunk['method'],\n",
        "            'url': chunk['url'],\n",
        "            'category': chunk['category'],\n",
        "            'description': chunk['description'],\n",
        "            'full_text': chunk['text']\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test the semantic search with sample queries\n",
        "test_queries = [\n",
        "    \"How do I fetch tweets with expansions?\",\n",
        "    \"authentication methods\",\n",
        "    \"rate limits for API\"\n",
        "]\n",
        "\n",
        "print(\"Testing semantic search:\\n\")\n",
        "for test_query in test_queries:\n",
        "    print(f\"Query: {test_query}\")\n",
        "    results = semantic_search(test_query, k=3)\n",
        "    for result in results:\n",
        "        print(f\"  {result['rank']}. {result['name']} (score: {result['score']:.3f})\")\n",
        "        print(f\"     {result['method']} {result['url'][:60]}...\")\n",
        "        print(f\"     {result['description']}\")\n",
        "        print(f\"     {result['full_text']}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "QPI3Wln1VB_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73bcce2a-f179-4de5-9560-df91aa51473e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing semantic search:\n",
            "\n",
            "Query: How do I fetch tweets with expansions?\n",
            "  1. Users by Username (score: 0.593)\n",
            "     GET https://api.twitter.com/2/users/by?usernames=...\n",
            "     \n",
            "     API: Users by Username\n",
            "Method: GET\n",
            "Endpoint: https://api.twitter.com/2/users/by?usernames=\n",
            "Category: User Lookup\n",
            "Parameters: usernames: Required. Enter up to 100 comma-separated usernames., user.fields: Comma-separated fields for the user object.\n",
            "\n",
            "Allowed values:\n",
            "created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld\n",
            "\n",
            "Default values:\n",
            "id,name,username, expansions: Expansions enable requests to expand an ID into a full object in the includes response object.\n",
            "\n",
            "Allowed value:\n",
            "pinned_tweet_id\n",
            "\n",
            "Default value: none, tweet.fields: Comma-separated list of fields for the Tweet object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,non_public_metrics,organic_metrics,possibly_sensitive,promoted_metrics,public_metrics,referenced_tweets,reply_settings,source,text,withheld\n",
            "\n",
            "Default values:\n",
            "id,text\n",
            "\n",
            "OAuth1.0a User Context authorization required if any of the following fields are included in the request:\n",
            "non_public_metrics,organic_metrics,promoted_metrics\n",
            "\n",
            "  2. Retweeted by (score: 0.587)\n",
            "     GET https://api.twitter.com/2/tweets/:id/retweeted_by...\n",
            "     \n",
            "     API: Retweeted by\n",
            "Method: GET\n",
            "Endpoint: https://api.twitter.com/2/tweets/:id/retweeted_by\n",
            "Category: Retweets\n",
            "Parameters: user.fields: Comma-separated fields for the user object.\n",
            "Allowed values:\n",
            "created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld\n",
            "Default values:\n",
            "id,name,username, expansions: Expansions enable requests to expand an ID into a full object in the includes response object.\n",
            "Allowed value:\n",
            "pinned_tweet_id\n",
            "Default value: none, tweet.fields: Comma-separated list of fields for the Tweet object. Expansion required.\n",
            "Allowed values:\n",
            "attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,non_public_metrics,organic_metrics,possibly_sensitive,promoted_metrics,public_metrics,referenced_tweets,source,text,withheld\n",
            "Default values:\n",
            "id,text\n",
            "OAuth1.0a User Context authorization required if any of the following fields are included in the request:\n",
            "non_public_metrics,organic_metrics,promoted_metrics\n",
            "\n",
            "  3. Users by ID (score: 0.584)\n",
            "     GET https://api.twitter.com/2/users?ids=...\n",
            "     \n",
            "     API: Users by ID\n",
            "Method: GET\n",
            "Endpoint: https://api.twitter.com/2/users?ids=\n",
            "Category: User Lookup\n",
            "Parameters: ids: Required. Enter up to 100 comma-separated user IDs., user.fields: Comma-separated fields for the user object.\n",
            "\n",
            "Allowed values:\n",
            "created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld\n",
            "\n",
            "Default values:\n",
            "id,name,username, expansions: Expansions enable requests to expand an ID into a full object in the includes response object.\n",
            "\n",
            "Allowed value:\n",
            "pinned_tweet_id\n",
            "\n",
            "Default value: none, tweet.fields: Comma-separated list of fields for the Tweet object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,non_public_metrics,organic_metrics,possibly_sensitive,promoted_metrics,public_metrics,referenced_tweets,reply_settings,source,text,withheld\n",
            "\n",
            "Default values:\n",
            "id,text\n",
            "\n",
            "OAuth1.0a User Context authorization required if any of the following fields are included in the request:\n",
            "non_public_metrics,organic_metrics,promoted_metrics\n",
            "\n",
            "\n",
            "Query: authentication methods\n",
            "  1. Block a user ID (score: 0.179)\n",
            "     POST https://api.twitter.com/2/users/:id/blocking...\n",
            "     \n",
            "     API: Block a user ID\n",
            "Method: POST\n",
            "Endpoint: https://api.twitter.com/2/users/:id/blocking\n",
            "Category: Blocks\n",
            "\n",
            "  2. Follow a user ID (score: 0.130)\n",
            "     POST https://api.twitter.com/2/users/:id/following...\n",
            "     \n",
            "     API: Follow a user ID\n",
            "Method: POST\n",
            "Endpoint: https://api.twitter.com/2/users/:id/following\n",
            "Category: Follows\n",
            "\n",
            "  3. Mute a user ID (score: 0.124)\n",
            "     POST https://api.twitter.com/2/users/:id/muting...\n",
            "     \n",
            "     API: Mute a user ID\n",
            "Method: POST\n",
            "Endpoint: https://api.twitter.com/2/users/:id/muting\n",
            "Category: Mutes\n",
            "\n",
            "\n",
            "Query: rate limits for API\n",
            "  1. User Tweet timeline by ID (score: 0.419)\n",
            "     GET https://api.twitter.com/2/users/:id/tweets...\n",
            "     \n",
            "     API: User Tweet timeline by ID\n",
            "Method: GET\n",
            "Endpoint: https://api.twitter.com/2/users/:id/tweets\n",
            "Category: Timelines\n",
            "Parameters: max_results: Specifies the number of Tweets to try and retrieve, up to a maximum of 100 per distinct request. \n",
            "\n",
            "Retweets and replies are included in the count, even if `exclude=retweets,replies` are supplied. \n",
            "\n",
            "By default, 10 results are returned if this parameter is not supplied. The minimum permitted value is 5.\n",
            ", start_time: YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339). The oldest or earliest UTC timestamp from which the Tweets will be provided. Only the 3200 most recent Tweets are available. Timestamp is in second granularity and is inclusive (i.e. 12:00:01 includes the first second of the minute). Minimum allowable time is 2010-11-06T00:00:00Z, end_time: YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339). The oldest or earliest UTC timestamp from which the Tweets will be provided. Only the 3200 most recent Tweets are available. Timestamp is in second granularity and is inclusive (i.e. 12:00:01 includes the first second of the minute). Minimum allowable time is 2010-11-06T00:00:00Z, since_id: Returns results with an ID greater than (that is, more recent than) the specified ID. Only the 3200 most recent Tweets are available. The result will exclude the `since_id`. If the limit of Tweets has occurred since the `since_id`, the `since_id` will be forced to the oldest ID available., until_id: Returns results with an ID less less than (that is, older than) the specified ID. Only the 3200 most recent Tweets are available. The result will exclude the `until_id`. If the limit of Tweets has occurred since the `until_id`, the `until_id` will be forced to the most recent ID available., pagination_token: This parameter is used to move forwards or backwards through pages of results, based on the value of the `next_token` or `previous_token` in the response. The value used with the parameter is pulled directly from the response provided by the API, and should not be modified., expansions: Comma-separated list of fields to expand. Expansions enable requests to expand an ID into a full object in the includes response object.\n",
            "\n",
            "Allowed values: attachments.poll_ids,attachments.media_keys,author_id,geo.place_id,in_reply_to_user_id,referenced_tweets.id,entities.mentions.username,referenced_tweets.id.author_id\n",
            "\n",
            "Default values: none, tweet.fields: Comma-separated list of fields for the Tweet object.\n",
            "\n",
            "Allowed values:\n",
            "attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,non_public_metrics,organic_metrics,possibly_sensitive,promoted_metrics,public_metrics,referenced_tweets,reply_settings,source,text,withheld\n",
            "\n",
            "Default values:\n",
            "id,text, user.fields: Comma-separated list of fields for the user object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld\n",
            "\n",
            "Default values:\n",
            "id,name,username, media.fields: Comma-separated list of fields for the media object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "duration_ms,height,media_key,non_public_metrics,organic_metrics,preview_image_url,promoted_metrics,public_metrics,type,url,width\n",
            "\n",
            "Default values:\n",
            "media_key,type, place.fields: Comma-separated list of fields for the place object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "contained_within,country,country_code,full_name,geo,id,name,place_type\n",
            "\n",
            "Default values:\n",
            "id,full_name, poll.fields: Comma-separated list of fields for the poll object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "duration_minutes,end_datetime,id,options,voting_status\n",
            "\n",
            "Default values:\n",
            "id, options\n",
            "\n",
            "  2. User mention timeline by ID (score: 0.408)\n",
            "     GET https://api.twitter.com/2/users/:id/mentions...\n",
            "     \n",
            "     API: User mention timeline by ID\n",
            "Method: GET\n",
            "Endpoint: https://api.twitter.com/2/users/:id/mentions\n",
            "Category: Timelines\n",
            "Parameters: max_results: Specifies the number of Tweets to try and retrieve, up to a maximum of 100 per distinct request. \n",
            "\n",
            "Retweets and replies are included in the count, even if `exclude=retweets,replies` are supplied. \n",
            "\n",
            "By default, 10 results are returned if this parameter is not supplied. The minimum permitted value is 5.\n",
            ", start_time: YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339). The oldest or earliest UTC timestamp from which the Tweets will be provided. Only the 3200 most recent Tweets are available. Timestamp is in second granularity and is inclusive (i.e. 12:00:01 includes the first second of the minute). Minimum allowable time is 2010-11-06T00:00:00Z, end_time: YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339). The oldest or earliest UTC timestamp from which the Tweets will be provided. Only the 3200 most recent Tweets are available. Timestamp is in second granularity and is inclusive (i.e. 12:00:01 includes the first second of the minute). Minimum allowable time is 2010-11-06T00:00:00Z, since_id: Returns results with an ID greater than (that is, more recent than) the specified ID. Only the 3200 most recent Tweets are available. The result will exclude the `since_id`. If the limit of Tweets has occurred since the `since_id`, the `since_id` will be forced to the oldest ID available., until_id: Returns results with an ID less less than (that is, older than) the specified ID. Only the 3200 most recent Tweets are available. The result will exclude the `until_id`. If the limit of Tweets has occurred since the `until_id`, the `until_id` will be forced to the most recent ID available., pagination_token: This parameter is used to move forwards or backwards through pages of results, based on the value of the `next_token` or `previous_token` in the response. The value used with the parameter is pulled directly from the response provided by the API, and should not be modified., expansions: Comma-separated list of fields to expand. Expansions enable requests to expand an ID into a full object in the includes response object.\n",
            "\n",
            "Allowed values: attachments.poll_ids,attachments.media_keys,author_id,geo.place_id,in_reply_to_user_id,referenced_tweets.id,entities.mentions.username,referenced_tweets.id.author_id\n",
            "\n",
            "Default values: none, tweet.fields: Comma-separated list of fields for the Tweet object.\n",
            "\n",
            "Allowed values:\n",
            "attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,non_public_metrics,organic_metrics,possibly_sensitive,promoted_metrics,public_metrics,referenced_tweets,reply_settings,source,text,withheld\n",
            "\n",
            "Default values:\n",
            "id,text, user.fields: Comma-separated list of fields for the user object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld\n",
            "\n",
            "Default values:\n",
            "id,name,username, media.fields: Comma-separated list of fields for the media object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "duration_ms,height,media_key,non_public_metrics,organic_metrics,preview_image_url,promoted_metrics,public_metrics,type,url,width\n",
            "\n",
            "Default values:\n",
            "media_key,type, place.fields: Comma-separated list of fields for the place object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "contained_within,country,country_code,full_name,geo,id,name,place_type\n",
            "\n",
            "Default values:\n",
            "id,full_name, poll.fields: Comma-separated list of fields for the poll object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "duration_minutes,end_datetime,id,options,voting_status\n",
            "\n",
            "Default values:\n",
            "id, options\n",
            "\n",
            "  3. Full-archive search (score: 0.346)\n",
            "     GET https://api.twitter.com/2/tweets/search/all?query=...\n",
            "     \n",
            "     API: Full-archive search\n",
            "Method: GET\n",
            "Endpoint: https://api.twitter.com/2/tweets/search/all?query=\n",
            "Category: Search Tweets\n",
            "Parameters: query: Required. Query for matching Tweets. Up to 1024 characters., start_time: The oldest UTC timestamp from which the Tweets will be provided. YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339)., end_time: The newest, most recent UTC timestamp to which the Tweets will be provided. YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339)., since_id: Returns results with a Tweet ID greater than (that is, more recent than) the specified ID. The ID specified is exclusive and responses will not include it., until_id: Returns results with a Tweet ID less than (that is, older than) the specified ID. The ID specified is exclusive and responses will not include it., max_results: The maximum number of search results to be returned by a request. A number between 10 and the system limit (currently 100). By default, a request response will return 10 results., next_token: This parameter is used to get the next 'page' of results. The value used with the parameter is pulled directly from the response provided by the API, and should not be modified., tweet.fields: Comma-separated list of fields for the Tweet object.\n",
            "\n",
            "Allowed values:\n",
            "attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,possibly_sensitive,public_metrics,referenced_tweets,reply_settings,source,text,withheld\n",
            "\n",
            "Default values:\n",
            "id,text\n",
            ", expansions: Comma-separated list of fields to expand. Expansions enable requests to expand an ID into a full object in the includes response object.\n",
            "\n",
            "Allowed values: attachments.poll_ids,attachments.media_keys,author_id,geo.place_id,in_reply_to_user_id,referenced_tweets.id,entities.mentions.username,referenced_tweets.id.author_id\n",
            "\n",
            "Default values: none, media.fields: Comma-separated list of fields for the media object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "duration_ms,height,media_key,preview_image_url,public_metrics,type,url,width\n",
            "\n",
            "Default values:\n",
            "media_key,type\n",
            ", place.fields: Comma-separated list of fields for the place object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "contained_within,country,country_code,full_name,geo,id,name,place_type\n",
            "\n",
            "Default values:\n",
            "id,full_name, poll.fields: Comma-separated list of fields for the poll object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "duration_minutes,end_datetime,id,options,voting_status\n",
            "\n",
            "Default values:\n",
            "id, options, user.fields: Comma-separated list of fields for the user object. Expansion required.\n",
            "\n",
            "Allowed values:\n",
            "created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld\n",
            "\n",
            "Default values:\n",
            "id,name,username\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Semantic Search as Standalone Script\n",
        "\n",
        "Creating the final semantic_search.py file that can be run from command line.\n"
      ],
      "metadata": {
        "id": "CA36qzmAVKnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the complete semantic_search.py script\n",
        "semantic_search_script = '''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Semantic Search Engine for Twitter API Documentation\n",
        "Kautilya ML Challenge - Task 1\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Parse Postman collection function\n",
        "def parse_postman_collection(collection_path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Parse Postman collection and extract documentation chunks.\"\"\"\n",
        "    chunks = []\n",
        "\n",
        "    try:\n",
        "        with open(collection_path, 'r', encoding='utf-8') as f:\n",
        "            collection = json.load(f)\n",
        "\n",
        "        def process_item(item, parent_name=\"\"):\n",
        "            \"\"\"Recursively process collection items.\"\"\"\n",
        "            if 'item' in item:\n",
        "                folder_name = item.get('name', '')\n",
        "                for sub_item in item['item']:\n",
        "                    process_item(sub_item, folder_name)\n",
        "            else:\n",
        "                request = item.get('request', {})\n",
        "                name = item.get('name', 'Unnamed')\n",
        "                description = item.get('description', '')\n",
        "                method = request.get('method', 'GET')\n",
        "\n",
        "                url_info = request.get('url', {})\n",
        "                url = url_info if isinstance(url_info, str) else url_info.get('raw', '')\n",
        "\n",
        "                query_params = []\n",
        "                if isinstance(url_info, dict) and 'query' in url_info:\n",
        "                    for param in url_info.get('query', []):\n",
        "                        param_name = param.get('key', '')\n",
        "                        param_desc = param.get('description', '')\n",
        "                        query_params.append(f\"{param_name}: {param_desc}\")\n",
        "\n",
        "                chunk_text = f\"API: {name}\\\\nMethod: {method}\\\\nEndpoint: {url}\\\\n\"\n",
        "                if parent_name:\n",
        "                    chunk_text += f\"Category: {parent_name}\\\\n\"\n",
        "                if description:\n",
        "                    chunk_text += f\"Description: {description}\\\\n\"\n",
        "                if query_params:\n",
        "                    chunk_text += f\"Parameters: {', '.join(query_params)}\\\\n\"\n",
        "\n",
        "                chunk = {\n",
        "                    'text': chunk_text,\n",
        "                    'name': name,\n",
        "                    'method': method,\n",
        "                    'url': url,\n",
        "                    'category': parent_name,\n",
        "                    'description': description\n",
        "                }\n",
        "                chunks.append(chunk)\n",
        "\n",
        "        if 'item' in collection:\n",
        "            for item in collection['item']:\n",
        "                process_item(item)\n",
        "\n",
        "        return chunks\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing collection: {e}\")\n",
        "        return []\n",
        "\n",
        "def build_search_system():\n",
        "    \"\"\"Build the semantic search system.\"\"\"\n",
        "    # Find collection files\n",
        "    collection_files = []\n",
        "    for root, dirs, files in os.walk('postman-twitter-api'):\n",
        "        for file in files:\n",
        "            if file.endswith('.json') and 'collection' in file.lower():\n",
        "                collection_files.append(os.path.join(root, file))\n",
        "\n",
        "    # Parse all collections\n",
        "    all_chunks = []\n",
        "    for collection_file in collection_files:\n",
        "        chunks = parse_postman_collection(collection_file)\n",
        "        all_chunks.extend(chunks)\n",
        "\n",
        "    # Load model and create embeddings\n",
        "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "    chunk_texts = [chunk['text'] for chunk in all_chunks]\n",
        "    embeddings = model.encode(chunk_texts, batch_size=32, show_progress_bar=False)\n",
        "    embeddings_normalized = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    # Build FAISS index\n",
        "    dimension = embeddings_normalized.shape[1]\n",
        "    index = faiss.IndexFlatIP(dimension)\n",
        "    index.add(embeddings_normalized.astype('float32'))\n",
        "\n",
        "    return model, index, all_chunks\n",
        "\n",
        "def search(query: str, model, index, chunks: List[Dict], k: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Perform semantic search.\"\"\"\n",
        "    query_embedding = model.encode([query])\n",
        "    query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
        "\n",
        "    scores, indices = index.search(query_embedding.astype('float32'), k)\n",
        "\n",
        "    results = []\n",
        "    for idx, score in zip(indices[0], scores[0]):\n",
        "        chunk = chunks[idx]\n",
        "        result = {\n",
        "            'rank': len(results) + 1,\n",
        "            'score': float(score),\n",
        "            'name': chunk['name'],\n",
        "            'method': chunk['method'],\n",
        "            'url': chunk['url'],\n",
        "            'category': chunk['category'],\n",
        "            'description': chunk['description']\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main entry point for command line usage.\"\"\"\n",
        "    parser = argparse.ArgumentParser(description='Semantic search over Twitter API documentation')\n",
        "    parser.add_argument('--query', required=True, help='Search query')\n",
        "    parser.add_argument('--k', type=int, default=5, help='Number of results to return')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Build search system\n",
        "    model, index, chunks = build_search_system()\n",
        "\n",
        "    # Perform search\n",
        "    results = search(args.query, model, index, chunks, args.k)\n",
        "\n",
        "    # Output as JSON\n",
        "    print(json.dumps(results, indent=2))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "# Save the script to file\n",
        "with open('semantic_search.py', 'w') as f:\n",
        "    f.write(semantic_search_script)\n",
        "\n",
        "print(\"semantic_search.py created successfully\")\n",
        "\n",
        "# Make it executable\n",
        "!chmod +x semantic_search.py\n",
        "\n",
        "# Test the script\n",
        "print(\"\\nTesting the script:\")\n",
        "!python semantic_search.py --query \"How do I fetch tweets with expansions?\" --k 3\n"
      ],
      "metadata": {
        "id": "NoztOoS9VIxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1611d2-2c93-415d-988a-4c7fc3208dd6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "semantic_search.py created successfully\n",
            "\n",
            "Testing the script:\n",
            "2025-11-17 09:19:07.529659: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763371147.602204    6039 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763371147.612288    6039 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763371147.645080    6039 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371147.645126    6039 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371147.645135    6039 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371147.645142    6039 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[\n",
            "  {\n",
            "    \"rank\": 1,\n",
            "    \"score\": 0.5931496620178223,\n",
            "    \"name\": \"Users by Username\",\n",
            "    \"method\": \"GET\",\n",
            "    \"url\": \"https://api.twitter.com/2/users/by?usernames=\",\n",
            "    \"category\": \"User Lookup\",\n",
            "    \"description\": \"\"\n",
            "  },\n",
            "  {\n",
            "    \"rank\": 2,\n",
            "    \"score\": 0.5870629549026489,\n",
            "    \"name\": \"Retweeted by\",\n",
            "    \"method\": \"GET\",\n",
            "    \"url\": \"https://api.twitter.com/2/tweets/:id/retweeted_by\",\n",
            "    \"category\": \"Retweets\",\n",
            "    \"description\": \"\"\n",
            "  },\n",
            "  {\n",
            "    \"rank\": 3,\n",
            "    \"score\": 0.584139347076416,\n",
            "    \"name\": \"Users by ID\",\n",
            "    \"method\": \"GET\",\n",
            "    \"url\": \"https://api.twitter.com/2/users?ids=\",\n",
            "    \"category\": \"User Lookup\",\n",
            "    \"description\": \"\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Narrative Building Setup\n",
        "\n",
        "For this task, we need to work with an 84MB news dataset. First, we need to obtain this dataset. Since the challenge document does not specify the exact source, we will create a placeholder for dataset loading.\n",
        "\n"
      ],
      "metadata": {
        "id": "twp3w_XBWCbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your news dataset\n",
        "# Replace this with the actual path provided in the challenge\n",
        "DATASET_PATH = \"news_dataset.json\"\n",
        "\n",
        "# If you need to download it from a URL, uncomment and modify:\n",
        "# !wget -O news_dataset.json \"YOUR_DATASET_URL_HERE\"\n",
        "\n",
        "# For demonstration, let us verify the file exists\n",
        "import os\n",
        "\n",
        "if os.path.exists(DATASET_PATH):\n",
        "    file_size = os.path.getsize(DATASET_PATH) / (1024 * 1024)\n",
        "    print(f\"Dataset found: {file_size:.2f} MB\")\n",
        "else:\n",
        "    print(f\"Dataset not found at {DATASET_PATH}\")\n",
        "    print(\"Please upload your news_dataset.json file or provide the correct path\")\n",
        "\n",
        "# If you have the dataset as a file, upload it using:\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# Then update DATASET_PATH accordingly\n"
      ],
      "metadata": {
        "id": "7w-kjaM3VOou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2188c129-ea5c-473c-92c2-73526e1a20ba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset found: 80.38 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "try:\n",
        "    with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "except json.JSONDecodeError as e:\n",
        "    print(\"JSON Error:\", e)\n",
        "    print(\"Line:\", e.lineno)\n",
        "    print(\"Column:\", e.colno)\n",
        "    print(\"Char index:\", e.pos)\n",
        "\n",
        "    # Show nearby lines for debugging\n",
        "    with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    start = max(0, e.lineno - 5)\n",
        "    end = min(len(lines), e.lineno + 5)\n",
        "\n",
        "    print(\"\\n--- Error Context ---\\n\")\n",
        "    for i in range(start, end):\n",
        "        print(f\"{i+1}: {lines[i].rstrip()}\")\n"
      ],
      "metadata": {
        "id": "ZUiUvSPLGl3c"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect Dataset Structure\n",
        "\n",
        "The dataset is loading but no articles are being filtered. Let's inspect the actual structure of your JSON file to understand the format.\n"
      ],
      "metadata": {
        "id": "wVaa443iZA9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and inspect the first few entries to understand the structure\n",
        "import json\n",
        "\n",
        "print(\"Inspecting dataset structure...\\n\")\n",
        "\n",
        "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Check the type and structure\n",
        "print(f\"Data type: {type(data)}\")\n",
        "\n",
        "if isinstance(data, dict):\n",
        "    print(f\"\\nTop-level keys: {list(data.keys())}\")\n",
        "\n",
        "    # Check if it contains an articles array\n",
        "    if 'articles' in data:\n",
        "        print(f\"Number of articles: {len(data['articles'])}\")\n",
        "        if data['articles']:\n",
        "            print(\"\\nSample article structure:\")\n",
        "            sample_article = data['articles'][0]\n",
        "            print(json.dumps(sample_article, indent=2)[:500])\n",
        "    else:\n",
        "        # Print sample of the structure\n",
        "        print(\"\\nSample of data structure:\")\n",
        "        print(json.dumps(data, indent=2)[:800])\n",
        "\n",
        "elif isinstance(data, list):\n",
        "    print(f\"\\nNumber of items in list: {len(data)}\")\n",
        "    if data:\n",
        "        print(\"\\nFirst item structure:\")\n",
        "        print(json.dumps(data[0], indent=2)[:500])\n",
        "else:\n",
        "    print(f\"\\nUnexpected data type: {type(data)}\")\n",
        "\n",
        "# Let's also check for nested structures\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Looking for rating fields...\")\n",
        "\n",
        "def find_rating_fields(obj, path=\"root\"):\n",
        "    \"\"\"\n",
        "    Recursively search for rating-related fields in the data structure.\n",
        "    \"\"\"\n",
        "    ratings_found = []\n",
        "\n",
        "    if isinstance(obj, dict):\n",
        "        for key, value in obj.items():\n",
        "            if 'rating' in key.lower() or 'score' in key.lower():\n",
        "                ratings_found.append(f\"{path}.{key}: {value}\")\n",
        "            if isinstance(value, (dict, list)):\n",
        "                ratings_found.extend(find_rating_fields(value, f\"{path}.{key}\"))\n",
        "    elif isinstance(obj, list) and obj:\n",
        "        for i, item in enumerate(obj[:3]):\n",
        "            ratings_found.extend(find_rating_fields(item, f\"{path}[{i}]\"))\n",
        "\n",
        "    return ratings_found\n",
        "\n",
        "ratings = find_rating_fields(data)\n",
        "if ratings:\n",
        "    print(\"Rating fields found:\")\n",
        "    for r in ratings[:10]:\n",
        "        print(f\"  {r}\")\n",
        "else:\n",
        "    print(\"No rating fields found in the dataset\")\n"
      ],
      "metadata": {
        "id": "XPdPHAEVY5uB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f2fe3ee-7527-4aa0-c9f3-443064148e51"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inspecting dataset structure...\n",
            "\n",
            "Data type: <class 'dict'>\n",
            "\n",
            "Top-level keys: ['items', 'updatedAt', 'last_updated', 'archived_at']\n",
            "\n",
            "Sample of data structure:\n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"title\": \"Hyderabad: Hyderabad Metro Rail Phase 2B DPR has been submitted to the central government: NVS Reddy\",\n",
            "      \"url\": \"https://www.eenadu.net/telugu-news/telangana/nvs-reddy-said-that-the-hyderabad-metro-phase-2b-dpr-has-been-submitted/1801/125111357\",\n",
            "      \"story\": \"Hyderabad: NVS Reddy, Managing Director of Hyderabad Airport Metro Rail Limited, announced that the Detailed Project Report (DPR) for the Hyderabad Metro Rail Phase 2B has been submitted to the central government along with all necessary documents. The Phase 2B project, recently approved by the state cabinet, includes three corridors: from RGIA to Bharat Future City (39.6 km; Rs. 7,168 crores), from JBS to Medchal (24.5 km; Rs. 6,946 crores), and from JBS to Shamirpet (22 km; Rs. 5,465 crore\n",
            "\n",
            "============================================================\n",
            "Looking for rating fields...\n",
            "Rating fields found:\n",
            "  root.items[0].source_rating: 7\n",
            "  root.items[1].source_rating: 8\n",
            "  root.items[2].source_rating: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Filter News Data\n",
        "\n",
        "Now that we understand the structure, the dataset has articles under the 'items' key with 'source_rating' field. Let's load and filter properly.\n"
      ],
      "metadata": {
        "id": "Z2ommN-zZYs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "def load_and_filter_news_data(filepath: str, min_rating: float = 8.0) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load news dataset and filter by source rating.\n",
        "    Dataset structure has articles under 'items' key.\n",
        "\n",
        "    Parameters:\n",
        "    filepath: Path to the JSON dataset\n",
        "    min_rating: Minimum source rating threshold\n",
        "\n",
        "    Returns:\n",
        "    List of filtered article dictionaries\n",
        "    \"\"\"\n",
        "    articles = []\n",
        "\n",
        "    try:\n",
        "        print(\"Loading dataset...\")\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Extract articles from 'items' key\n",
        "        if 'items' in data and isinstance(data['items'], list):\n",
        "            raw_articles = data['items']\n",
        "            print(f\"Total articles in dataset: {len(raw_articles)}\")\n",
        "        else:\n",
        "            print(\"Error: 'items' key not found in dataset\")\n",
        "            return []\n",
        "\n",
        "        # Filter by source rating\n",
        "        for article in raw_articles:\n",
        "            if not isinstance(article, dict):\n",
        "                continue\n",
        "\n",
        "            # Extract source rating\n",
        "            source_rating = article.get('source_rating')\n",
        "\n",
        "            # Convert to float if possible\n",
        "            try:\n",
        "                if source_rating is not None:\n",
        "                    source_rating = float(source_rating)\n",
        "                else:\n",
        "                    continue\n",
        "            except (ValueError, TypeError):\n",
        "                continue\n",
        "\n",
        "            # Apply filter\n",
        "            if source_rating > min_rating:\n",
        "                # Standardize article structure\n",
        "                # Based on the structure, we have: title, url, story, source_rating\n",
        "                standardized = {\n",
        "                    'headline': article.get('title', ''),\n",
        "                    'content': article.get('story', ''),\n",
        "                    'url': article.get('url', ''),\n",
        "                    'date': article.get('date') or article.get('published_at') or article.get('publishedAt') or article.get('timestamp', ''),\n",
        "                    'source': article.get('source', ''),\n",
        "                    'source_rating': source_rating,\n",
        "                    'author': article.get('author', ''),\n",
        "                    'category': article.get('category', '')\n",
        "                }\n",
        "                articles.append(standardized)\n",
        "\n",
        "        print(f\"Articles after filtering (rating > {min_rating}): {len(articles)}\")\n",
        "\n",
        "        if articles:\n",
        "            ratings = [a['source_rating'] for a in articles]\n",
        "            print(f\"Rating range: {min(ratings):.1f} - {max(ratings):.1f}\")\n",
        "\n",
        "        return articles\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File {filepath} not found\")\n",
        "        return []\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return []\n",
        "\n",
        "# Load and filter the dataset\n",
        "print(\"Starting data loading and filtering...\\n\")\n",
        "filtered_articles = load_and_filter_news_data(DATASET_PATH, min_rating=8.0)\n",
        "\n",
        "if filtered_articles:\n",
        "    print(f\"\\n Successfully loaded {len(filtered_articles)} high-quality articles\")\n",
        "    print(\"\\nSample article:\")\n",
        "    sample = filtered_articles[0]\n",
        "    print(f\"Headline: {sample['headline'][:100]}...\")\n",
        "    print(f\"Date: {sample['date']}\")\n",
        "    print(f\"Source: {sample['source']} (Rating: {sample['source_rating']})\")\n",
        "    print(f\"Content preview: {sample['content'][:200]}...\")\n",
        "else:\n",
        "    print(\"\\n✗ No articles loaded. Please check the dataset.\")\n"
      ],
      "metadata": {
        "id": "a26JJnZDZZqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d10faa-69dd-422f-9501-37a81671132f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data loading and filtering...\n",
            "\n",
            "Loading dataset...\n",
            "Total articles in dataset: 36483\n",
            "Articles after filtering (rating > 8.0): 2685\n",
            "Rating range: 9.0 - 10.0\n",
            "\n",
            " Successfully loaded 2685 high-quality articles\n",
            "\n",
            "Sample article:\n",
            "Headline: Honeymoon murder case: Meghalaya court remands Sonam, Raj to 13-day judicial custody - details...\n",
            "Date: 2025-06-21T20:39:00Z\n",
            "Source:  (Rating: 9.0)\n",
            "Content preview: Sonam Raghuvanshi and Raj Kushwaha have been remanded to judicial custody for the murder of Raja Raghuvanshi during their honeymoon in Meghalaya. Arrested along with three accomplices, they are under ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Articles by Topic\n",
        "\n",
        "Use semantic similarity to find articles relevant to any user-provided topic. This works dynamically for any topic query.\n"
      ],
      "metadata": {
        "id": "nberxSeKZgNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_articles_by_topic(articles: List[Dict], topic_query: str, threshold: float = 0.3) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Filter articles relevant to a specific topic using semantic similarity.\n",
        "\n",
        "    Parameters:\n",
        "    articles: List of article dictionaries\n",
        "    topic_query: The topic to search for\n",
        "    threshold: Minimum similarity score to consider relevant\n",
        "\n",
        "    Returns:\n",
        "    List of relevant articles with similarity scores\n",
        "    \"\"\"\n",
        "    if not articles:\n",
        "        return []\n",
        "\n",
        "    print(f\"Filtering {len(articles)} articles for topic: '{topic_query}'\")\n",
        "    print(f\"Similarity threshold: {threshold}\")\n",
        "\n",
        "    # Encode the topic query\n",
        "    topic_embedding = model.encode([topic_query], convert_to_numpy=True)\n",
        "    topic_embedding = topic_embedding / np.linalg.norm(topic_embedding)\n",
        "\n",
        "    # Prepare article texts for embedding\n",
        "    # Combine headline and first portion of content for better relevance\n",
        "    article_texts = []\n",
        "    for article in articles:\n",
        "        # Handle cases where content might be empty\n",
        "        content_preview = article['content'][:300] if article['content'] else ''\n",
        "        text = f\"{article['headline']} {content_preview}\"\n",
        "        article_texts.append(text)\n",
        "\n",
        "    # Batch encode all articles\n",
        "    print(\"Computing embeddings for articles...\")\n",
        "    article_embeddings = model.encode(\n",
        "        article_texts,\n",
        "        batch_size=32,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True\n",
        "    )\n",
        "\n",
        "    # Normalize embeddings\n",
        "    article_embeddings = article_embeddings / np.linalg.norm(article_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    # Compute similarity scores\n",
        "    similarities = np.dot(article_embeddings, topic_embedding.T).flatten()\n",
        "\n",
        "    # Filter and sort by relevance\n",
        "    relevant_articles = []\n",
        "    for idx, (article, score) in enumerate(zip(articles, similarities)):\n",
        "        if score >= threshold:\n",
        "            article_with_score = article.copy()\n",
        "            article_with_score['relevance_score'] = float(score)\n",
        "            relevant_articles.append(article_with_score)\n",
        "\n",
        "    # Sort by relevance score descending\n",
        "    relevant_articles.sort(key=lambda x: x['relevance_score'], reverse=True)\n",
        "\n",
        "    print(f\"Found {len(relevant_articles)} relevant articles\")\n",
        "\n",
        "    if relevant_articles:\n",
        "        print(f\"Top relevance score: {relevant_articles[0]['relevance_score']:.3f}\")\n",
        "        print(f\"Lowest relevance score: {relevant_articles[-1]['relevance_score']:.3f}\")\n",
        "\n",
        "    return relevant_articles\n",
        "\n",
        "# Test with a sample topic if we have articles\n",
        "if filtered_articles:\n",
        "    test_topic = \"Hyderabad Metro Rail expansion\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Testing topic filtering with: '{test_topic}'\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    relevant_test = filter_articles_by_topic(filtered_articles[:500], test_topic, threshold=0.25)\n",
        "\n",
        "    if relevant_test:\n",
        "        print(f\"\\nTop 5 most relevant articles:\")\n",
        "        for i, article in enumerate(relevant_test[:5], 1):\n",
        "            print(f\"{i}. {article['headline'][:70]}...\")\n",
        "            print(f\"   Score: {article['relevance_score']:.3f}\\n\")\n"
      ],
      "metadata": {
        "id": "Eq0ruuh-Zf8u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535,
          "referenced_widgets": [
            "17c51a675d7844d684c9c723998d3814",
            "82f4c4504a35437e9b09bef32a0e6759",
            "96e3c5be5ad7402f8a0a50150787f702",
            "a6ca3c0bc7674a789484741b83bf9d44",
            "77541d7ceb0d4b37bcd1e6597c5e11d5",
            "e8f3f0a3c405422c9d17f209286762fc",
            "b761c71cd4164192892012ec9ad9f1fd",
            "7bac09121502434dbd7cd55b36966fba",
            "306431d2a46b4a68aeff67841592e0cb",
            "29f0fad8abc049b1a95ded56320ecc6d",
            "b85fc1486ba743f4acbeb64fe8267857"
          ]
        },
        "outputId": "2882d473-853f-4ae7-fa12-5d1fc2463312"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Testing topic filtering with: 'Hyderabad Metro Rail expansion'\n",
            "============================================================\n",
            "\n",
            "Filtering 500 articles for topic: 'Hyderabad Metro Rail expansion'\n",
            "Similarity threshold: 0.25\n",
            "Computing embeddings for articles...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17c51a675d7844d684c9c723998d3814"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 84 relevant articles\n",
            "Top relevance score: 0.526\n",
            "Lowest relevance score: 0.250\n",
            "\n",
            "Top 5 most relevant articles:\n",
            "1. Telangana developers body bats for suburban master plan of Hyderabad; ...\n",
            "   Score: 0.526\n",
            "\n",
            "2. Indian Railways hikes fares of passenger trains; minor increase in tic...\n",
            "   Score: 0.524\n",
            "\n",
            "3. Indian Railways notifies minor fare hike: New ticket prices effective ...\n",
            "   Score: 0.503\n",
            "\n",
            "4. Greater Hyderabad Municipal Corporation (GHMC) launches Rs 45 crore ro...\n",
            "   Score: 0.488\n",
            "\n",
            "5. Minister Jupally Krishna Rao to inaugurate 14 new excise stations acro...\n",
            "   Score: 0.479\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Narrative Summary\n",
        "\n",
        "Create a coherent narrative summary from the most relevant articles using extractive summarization techniques.\n"
      ],
      "metadata": {
        "id": "8LxYwtIRZl4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
        "import re\n",
        "\n",
        "def generate_narrative_summary(articles: List[Dict], topic: str, num_sentences: int = 7) -> str:\n",
        "    \"\"\"\n",
        "    Generate a narrative summary from relevant articles.\n",
        "    Uses extractive summarization to create coherent narrative.\n",
        "\n",
        "    Parameters:\n",
        "    articles: List of relevant article dictionaries\n",
        "    topic: The topic being summarized\n",
        "    num_sentences: Target number of sentences in summary\n",
        "\n",
        "    Returns:\n",
        "    Narrative summary string\n",
        "    \"\"\"\n",
        "    if not articles:\n",
        "        return f\"No articles found relevant to {topic}.\"\n",
        "\n",
        "    print(f\"Generating narrative summary from {len(articles)} articles...\")\n",
        "\n",
        "    # Collect all sentences from top articles\n",
        "    all_sentences = []\n",
        "\n",
        "    # Use top 15 most relevant articles\n",
        "    top_articles = articles[:min(15, len(articles))]\n",
        "\n",
        "    for article in top_articles:\n",
        "        content = article.get('content', '')\n",
        "\n",
        "        if not content:\n",
        "            continue\n",
        "\n",
        "        # Split into sentences using regex\n",
        "        # Split on period, exclamation, or question mark followed by space and capital letter\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z])', content)\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            # Only include sentences with reasonable length\n",
        "            if 10 < len(sentence.split()) < 50:\n",
        "                all_sentences.append(sentence)\n",
        "\n",
        "    if not all_sentences:\n",
        "        # Fallback: use headlines\n",
        "        summary_parts = [a['headline'] for a in top_articles[:num_sentences]]\n",
        "        return ' '.join(summary_parts)\n",
        "\n",
        "    # Limit to reasonable number for processing\n",
        "    all_sentences = all_sentences[:min(300, len(all_sentences))]\n",
        "\n",
        "    print(f\"Analyzing {len(all_sentences)} sentences...\")\n",
        "\n",
        "    # Create TF-IDF matrix\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer(stop_words='english', max_features=1000, min_df=1)\n",
        "        tfidf_matrix = vectorizer.fit_transform(all_sentences)\n",
        "\n",
        "        # Encode topic query\n",
        "        topic_vector = vectorizer.transform([topic])\n",
        "\n",
        "        # Calculate similarity of each sentence to the topic\n",
        "        similarities = cos_sim(tfidf_matrix, topic_vector).flatten()\n",
        "\n",
        "        # Get top sentences\n",
        "        top_indices = np.argsort(similarities)[-num_sentences:][::-1]\n",
        "\n",
        "        # Sort by original order for coherence\n",
        "        top_indices_sorted = sorted(top_indices)\n",
        "\n",
        "        # Extract sentences\n",
        "        summary_sentences = [all_sentences[idx] for idx in top_indices_sorted]\n",
        "\n",
        "        # Combine into narrative\n",
        "        summary = ' '.join(summary_sentences)\n",
        "\n",
        "        print(f\"Summary generated: {len(summary.split())} words\")\n",
        "\n",
        "        return summary\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in summarization: {e}\")\n",
        "        # Fallback: take first sentences from top articles\n",
        "        fallback_sentences = []\n",
        "        for article in top_articles[:num_sentences]:\n",
        "            if article['content']:\n",
        "                first_sent = article['content'].split('.')[0] + '.'\n",
        "                fallback_sentences.append(first_sent)\n",
        "        return ' '.join(fallback_sentences)\n",
        "\n",
        "# Test summary generation\n",
        "if filtered_articles and relevant_test:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Testing narrative summary generation\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    test_summary = generate_narrative_summary(relevant_test, test_topic)\n",
        "    print(f\"\\nGenerated Summary:\\n{test_summary[:500]}...\\n\")\n"
      ],
      "metadata": {
        "id": "nvP4aFLaZm6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f79079-ab00-47ac-fed1-caac5eaa587d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Testing narrative summary generation\n",
            "============================================================\n",
            "\n",
            "Generating narrative summary from 84 articles...\n",
            "Analyzing 148 sentences...\n",
            "Summary generated: 181 words\n",
            "\n",
            "Generated Summary:\n",
            "The Telangana Developers Association (TDA) has called on the Telangana government to develop a suburban master plan for Hyderabad to ensure balanced expansion across all four sides of the city. Rao also mentioned that the Regional Ring Road (RRR), Future City, and Metro Rail expansion could significantly boost Hyderabad's economic activity, with the RRR having great potential to enhance the city's economic landscape. The Greater Hyderabad Municipal Corporation (GHMC) has initiated a road expansi...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Event Timeline\n",
        "\n",
        "Create a chronological timeline of events with context on why each article matters to the narrative.\n",
        "\n",
        "**Note:** Here we have to handle timezone-aware and timezone-naive datetime objects properly to avoid comparison errors.\n"
      ],
      "metadata": {
        "id": "DtQdDjP1aOXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dateutil.parser\n",
        "from datetime import timezone\n",
        "\n",
        "def build_timeline(articles: List[Dict], topic: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Build chronological timeline of events from articles.\n",
        "\n",
        "    Parameters:\n",
        "    articles: List of relevant article dictionaries\n",
        "    topic: The topic being analyzed\n",
        "\n",
        "    Returns:\n",
        "    List of timeline events sorted by date\n",
        "    \"\"\"\n",
        "    print(f\"Building timeline from {len(articles)} articles...\")\n",
        "\n",
        "    timeline = []\n",
        "\n",
        "    for article in articles:\n",
        "        # Parse date\n",
        "        date_str = article.get('date', '')\n",
        "        parsed_date = None\n",
        "        formatted_date = 'Unknown'\n",
        "\n",
        "        if date_str:\n",
        "            try:\n",
        "                parsed_date = dateutil.parser.parse(date_str)\n",
        "\n",
        "                # Convert to timezone-aware if naive to ensure consistent comparison\n",
        "                if parsed_date.tzinfo is None:\n",
        "                    parsed_date = parsed_date.replace(tzinfo=timezone.utc)\n",
        "\n",
        "                formatted_date = parsed_date.strftime('%Y-%m-%d')\n",
        "            except:\n",
        "                # If parsing fails, try to extract date string directly\n",
        "                try:\n",
        "                    formatted_date = str(date_str)[:10] if date_str else 'Unknown'\n",
        "                except:\n",
        "                    formatted_date = 'Unknown'\n",
        "\n",
        "        # Generate why_it_matters explanation\n",
        "        relevance_score = article.get('relevance_score', 0)\n",
        "\n",
        "        # Create contextual explanation based on relevance\n",
        "        if relevance_score > 0.6:\n",
        "            importance = \"Highly relevant\"\n",
        "        elif relevance_score > 0.4:\n",
        "            importance = \"Moderately relevant\"\n",
        "        else:\n",
        "            importance = \"Provides context\"\n",
        "\n",
        "        # Extract key insight from content or headline\n",
        "        content = article.get('content', '')\n",
        "        if content and len(content) > 50:\n",
        "            # Take first sentence\n",
        "            first_sentence = content.split('.')[0].strip()\n",
        "            if len(first_sentence) > 100:\n",
        "                first_sentence = first_sentence[:100] + '...'\n",
        "        else:\n",
        "            first_sentence = article['headline'][:100]\n",
        "\n",
        "        why_it_matters = f\"{importance} to {topic}. {first_sentence}\"\n",
        "\n",
        "        event = {\n",
        "            'date': formatted_date,\n",
        "            'headline': article['headline'],\n",
        "            'url': article['url'],\n",
        "            'why_it_matters': why_it_matters,\n",
        "            'source': article.get('source', 'Unknown'),\n",
        "            'parsed_date': parsed_date\n",
        "        }\n",
        "\n",
        "        timeline.append(event)\n",
        "\n",
        "    # Separate events with valid dates from those without\n",
        "    timeline_with_dates = [e for e in timeline if e['parsed_date'] is not None]\n",
        "    timeline_without_dates = [e for e in timeline if e['parsed_date'] is None]\n",
        "\n",
        "    # Sort events with dates chronologically\n",
        "    if timeline_with_dates:\n",
        "        try:\n",
        "            timeline_with_dates.sort(key=lambda x: x['parsed_date'])\n",
        "        except TypeError as e:\n",
        "            # If comparison still fails, convert all to UTC\n",
        "            print(f\"Warning: Mixed timezone dates detected, normalizing to UTC\")\n",
        "            for event in timeline_with_dates:\n",
        "                if event['parsed_date'].tzinfo is None:\n",
        "                    event['parsed_date'] = event['parsed_date'].replace(tzinfo=timezone.utc)\n",
        "                else:\n",
        "                    event['parsed_date'] = event['parsed_date'].astimezone(timezone.utc)\n",
        "            timeline_with_dates.sort(key=lambda x: x['parsed_date'])\n",
        "\n",
        "    # Remove parsed_date field before returning\n",
        "    for event in timeline_with_dates + timeline_without_dates:\n",
        "        if 'parsed_date' in event:\n",
        "            del event['parsed_date']\n",
        "\n",
        "    final_timeline = timeline_with_dates + timeline_without_dates\n",
        "\n",
        "    print(f\"Timeline created with {len(final_timeline)} events\")\n",
        "    if timeline_with_dates:\n",
        "        print(f\"Date range: {final_timeline[0]['date']} to {final_timeline[len(timeline_with_dates)-1]['date']}\")\n",
        "\n",
        "    return final_timeline\n",
        "\n",
        "# Test timeline building\n",
        "if filtered_articles and relevant_test:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Testing timeline construction\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    test_timeline = build_timeline(relevant_test[:20], test_topic)\n",
        "    print(f\"\\nFirst 3 timeline events:\\n\")\n",
        "    for i, event in enumerate(test_timeline[:3], 1):\n",
        "        print(f\"{i}. [{event['date']}] {event['headline'][:60]}...\")\n",
        "        print(f\"   Source: {event['source']}\")\n",
        "        print(f\"   Why: {event['why_it_matters'][:100]}...\\n\")\n"
      ],
      "metadata": {
        "id": "dSasw-rOaOHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e4827d-1a12-4e9d-f7a0-8d74bc382778"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Testing timeline construction\n",
            "============================================================\n",
            "\n",
            "Building timeline from 20 articles...\n",
            "Timeline created with 20 events\n",
            "Date range: 2025-06-21 to 2025-06-30\n",
            "\n",
            "First 3 timeline events:\n",
            "\n",
            "1. [2025-06-21] Telangana developers body bats for suburban master plan of H...\n",
            "   Source: \n",
            "   Why: Moderately relevant to Hyderabad Metro Rail expansion. The Telangana Developers Association (TDA) ha...\n",
            "\n",
            "2. [2025-06-23] Operation Sindhu: Flight with 285 evacuees from Iran lands i...\n",
            "   Source: \n",
            "   Why: Provides context to Hyderabad Metro Rail expansion. Under Operation Sindhu, a special flight carryin...\n",
            "\n",
            "3. [2025-06-23] Healthcare push: Telangana to establish cancer care centres ...\n",
            "   Source: \n",
            "   Why: Provides context to Hyderabad Metro Rail expansion. Telangana's health minister announced plans to e...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Narrative Graph\n",
        "\n",
        "Construct a graph showing relationships between articles including temporal progression and semantic connections.\n",
        "\n",
        "The graph identifies four types of relationships:\n",
        "- **builds_on**: Temporal and semantic continuation\n",
        "- **contradicts**: Conflicting information  \n",
        "- **adds_context**: Background or supporting information\n",
        "- **escalates**: Increasing severity or progression\n"
      ],
      "metadata": {
        "id": "M7sFT2EYalx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def build_narrative_graph(articles: List[Dict]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Build a narrative graph showing relationships between articles.\n",
        "\n",
        "    Parameters:\n",
        "    articles: List of relevant article dictionaries\n",
        "\n",
        "    Returns:\n",
        "    Graph dictionary with nodes and edges\n",
        "    \"\"\"\n",
        "    print(f\"Building narrative graph for {len(articles)} articles...\")\n",
        "\n",
        "    # Create nodes\n",
        "    nodes = []\n",
        "    for idx, article in enumerate(articles):\n",
        "        node = {\n",
        "            'id': idx,\n",
        "            'headline': article['headline'],\n",
        "            'date': article.get('date', 'Unknown'),\n",
        "            'url': article['url']\n",
        "        }\n",
        "        nodes.append(node)\n",
        "\n",
        "    # Generate embeddings for all articles\n",
        "    article_texts = []\n",
        "    for a in articles:\n",
        "        content_preview = a.get('content', '')[:300]\n",
        "        text = f\"{a['headline']} {content_preview}\"\n",
        "        article_texts.append(text)\n",
        "\n",
        "    print(\"Computing embeddings for graph construction...\")\n",
        "    embeddings = model.encode(article_texts, batch_size=32, show_progress_bar=False)\n",
        "    embeddings_norm = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    # Compute pairwise similarities\n",
        "    similarity_matrix = np.dot(embeddings_norm, embeddings_norm.T)\n",
        "\n",
        "    # Parse dates for temporal analysis\n",
        "    dates = []\n",
        "    for article in articles:\n",
        "        try:\n",
        "            if article.get('date'):\n",
        "                parsed = dateutil.parser.parse(article['date'])\n",
        "                # Make timezone-aware if needed\n",
        "                if parsed.tzinfo is None:\n",
        "                    parsed = parsed.replace(tzinfo=timezone.utc)\n",
        "                dates.append(parsed)\n",
        "            else:\n",
        "                dates.append(None)\n",
        "        except:\n",
        "            dates.append(None)\n",
        "\n",
        "    # Define keywords for relationship detection\n",
        "    escalation_keywords = ['escalate', 'intensif', 'worsen', 'increase', 'grow', 'expand',\n",
        "                          'crisis', 'critical', 'urgent', 'severe', 'major']\n",
        "    context_keywords = ['background', 'history', 'context', 'previously', 'earlier',\n",
        "                       'origin', 'initially', 'first', 'began']\n",
        "    contradiction_keywords = ['however', 'but', 'contrary', 'dispute', 'deny', 'refute',\n",
        "                             'oppose', 'contradict', 'disagree']\n",
        "\n",
        "    edges = []\n",
        "\n",
        "    # Build edges based on relationships\n",
        "    # Only process pairs to avoid too many edges\n",
        "    for i in range(len(articles)):\n",
        "        for j in range(i + 1, len(articles)):\n",
        "            similarity = similarity_matrix[i][j]\n",
        "\n",
        "            # Only consider pairs with meaningful similarity\n",
        "            if similarity < 0.35:\n",
        "                continue\n",
        "\n",
        "            article_i = articles[i]\n",
        "            article_j = articles[j]\n",
        "\n",
        "            # Determine temporal ordering\n",
        "            if dates[i] and dates[j]:\n",
        "                try:\n",
        "                    is_i_before_j = dates[i] < dates[j]\n",
        "                    days_apart = abs((dates[j] - dates[i]).days)\n",
        "                except:\n",
        "                    is_i_before_j = True\n",
        "                    days_apart = 0\n",
        "            else:\n",
        "                is_i_before_j = True\n",
        "                days_apart = 0\n",
        "\n",
        "            # Analyze content for relationship type\n",
        "            content_i = article_i.get('content', '').lower()\n",
        "            content_j = article_j.get('content', '').lower()\n",
        "            headline_j = article_j['headline'].lower()\n",
        "\n",
        "            # Detect relationship type\n",
        "            relationship_type = None\n",
        "\n",
        "            # Check for contradiction\n",
        "            has_contradiction = any(kw in content_j or kw in headline_j\n",
        "                                   for kw in contradiction_keywords)\n",
        "            if has_contradiction and similarity > 0.5:\n",
        "                relationship_type = 'contradicts'\n",
        "\n",
        "            # Check for escalation\n",
        "            elif any(kw in content_j or kw in headline_j\n",
        "                    for kw in escalation_keywords) and is_i_before_j and similarity > 0.55:\n",
        "                relationship_type = 'escalates'\n",
        "\n",
        "            # Check for context building\n",
        "            elif any(kw in content_j or kw in headline_j\n",
        "                    for kw in context_keywords) and similarity > 0.4:\n",
        "                relationship_type = 'adds_context'\n",
        "\n",
        "            # Default to builds_on for high similarity temporal progression\n",
        "            elif is_i_before_j and similarity > 0.55 and days_apart < 60:\n",
        "                relationship_type = 'builds_on'\n",
        "\n",
        "            # Only add edge if relationship identified\n",
        "            if relationship_type:\n",
        "                edge = {\n",
        "                    'source': i,\n",
        "                    'target': j,\n",
        "                    'type': relationship_type,\n",
        "                    'similarity': float(similarity)\n",
        "                }\n",
        "                edges.append(edge)\n",
        "\n",
        "    print(f\"Created graph with {len(nodes)} nodes and {len(edges)} edges\")\n",
        "\n",
        "    # Analyze edge type distribution\n",
        "    edge_types = Counter([e['type'] for e in edges])\n",
        "    print(f\"Edge distribution: {dict(edge_types)}\")\n",
        "\n",
        "    graph = {\n",
        "        'nodes': nodes,\n",
        "        'edges': edges,\n",
        "        'stats': {\n",
        "            'num_nodes': len(nodes),\n",
        "            'num_edges': len(edges),\n",
        "            'edge_types': dict(edge_types)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return graph\n",
        "\n",
        "# Test graph construction\n",
        "if filtered_articles and relevant_test and len(relevant_test) >= 5:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Testing narrative graph construction\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    test_graph = build_narrative_graph(relevant_test[:25])\n",
        "    print(f\"\\nGraph statistics:\")\n",
        "    print(f\"Nodes: {test_graph['stats']['num_nodes']}\")\n",
        "    print(f\"Edges: {test_graph['stats']['num_edges']}\")\n",
        "    print(f\"Edge types: {test_graph['stats']['edge_types']}\")\n",
        "\n",
        "    if test_graph['edges']:\n",
        "        print(f\"\\nSample edges:\")\n",
        "        for edge in test_graph['edges'][:3]:\n",
        "            source_headline = test_graph['nodes'][edge['source']]['headline'][:40]\n",
        "            target_headline = test_graph['nodes'][edge['target']]['headline'][:40]\n",
        "            print(f\"  {source_headline}... --[{edge['type']}]--> {target_headline}...\")"
      ],
      "metadata": {
        "id": "2RgQBBopanib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472f4b61-84cb-4644-9745-02ffa5c69564"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Testing narrative graph construction\n",
            "============================================================\n",
            "\n",
            "Building narrative graph for 25 articles...\n",
            "Computing embeddings for graph construction...\n",
            "Created graph with 25 nodes and 26 edges\n",
            "Edge distribution: {'adds_context': 17, 'contradicts': 6, 'escalates': 3}\n",
            "\n",
            "Graph statistics:\n",
            "Nodes: 25\n",
            "Edges: 26\n",
            "Edge types: {'adds_context': 17, 'contradicts': 6, 'escalates': 3}\n",
            "\n",
            "Sample edges:\n",
            "  Telangana developers body bats for subur... --[adds_context]--> Operation Sindhu: 17 more from Telangana...\n",
            "  Telangana developers body bats for subur... --[adds_context]--> Hyderabad set for major infra push: Govt...\n",
            "  Telangana developers body bats for subur... --[contradicts]--> Telangana DOST Phase-III: Over 85K UG se...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Narrative Builder as Standalone Script\n",
        "\n",
        "Creating the final narrative_builder.py file that can be run from command line with any topic.\n"
      ],
      "metadata": {
        "id": "piueAV7bbBRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the complete narrative_builder.py script\n",
        "narrative_builder_script = '''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Narrative Builder from News Dataset\n",
        "Kautilya ML Challenge - Task 2\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "from datetime import timezone\n",
        "from typing import List, Dict, Any\n",
        "from collections import Counter\n",
        "import re\n",
        "import sys # Added import sys\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
        "import dateutil.parser\n",
        "\n",
        "# Load sentence transformer model globally\n",
        "print(\"Loading sentence transformer model...\", file=sys.stderr) # Modified\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "print(\"Model loaded\", file=sys.stderr) # Modified\n",
        "\n",
        "def load_and_filter_news_data(filepath: str, min_rating: float = 8.0) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load news dataset and filter by source rating.\"\"\"\n",
        "    articles = []\n",
        "\n",
        "    try: # Added try-except for file loading\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset file not found at {filepath}\", file=sys.stderr)\n",
        "        return []\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON from {filepath}: {e}\", file=sys.stderr)\n",
        "        return []\n",
        "\n",
        "    if 'items' in data and isinstance(data['items'], list):\n",
        "        raw_articles = data['items']\n",
        "    else:\n",
        "        print(\"Error: 'items' key not found in dataset or is not a list.\", file=sys.stderr) # Modified\n",
        "        return []\n",
        "\n",
        "    for article in raw_articles:\n",
        "        if not isinstance(article, dict):\n",
        "            continue\n",
        "\n",
        "        source_rating = article.get('source_rating')\n",
        "\n",
        "        try:\n",
        "            if source_rating is not None:\n",
        "                source_rating = float(source_rating)\n",
        "            else:\n",
        "                continue\n",
        "        except (ValueError, TypeError):\n",
        "            continue\n",
        "\n",
        "        if source_rating > min_rating:\n",
        "            standardized = {\n",
        "                'headline': article.get('title', ''),\n",
        "                'content': article.get('story', ''),\n",
        "                'url': article.get('url', ''),\n",
        "                'date': article.get('date', ''),\n",
        "                'source': article.get('source', ''),\n",
        "                'source_rating': source_rating,\n",
        "                'author': article.get('author', ''),\n",
        "                'category': article.get('category', '')\n",
        "            }\n",
        "            articles.append(standardized)\n",
        "\n",
        "    return articles\n",
        "\n",
        "def filter_articles_by_topic(articles: List[Dict], topic_query: str, threshold: float = 0.3) -> List[Dict]:\n",
        "    \"\"\"Filter articles relevant to a specific topic using semantic similarity.\"\"\"\n",
        "    if not articles:\n",
        "        return []\n",
        "\n",
        "    print(f\"Filtering {len(articles)} articles for topic: '{topic_query}'\", file=sys.stderr) # Modified\n",
        "    print(f\"Similarity threshold: {threshold}\", file=sys.stderr) # Modified\n",
        "\n",
        "    topic_embedding = model.encode([topic_query], convert_to_numpy=True)\n",
        "    topic_embedding = topic_embedding / np.linalg.norm(topic_embedding)\n",
        "\n",
        "    article_texts = []\n",
        "    for article in articles:\n",
        "        content_preview = article['content'][:300] if article['content'] else ''\n",
        "        text = f\"{article['headline']} {content_preview}\"\n",
        "        article_texts.append(text)\n",
        "\n",
        "    print(\"Computing embeddings for articles...\", file=sys.stderr) # Modified\n",
        "    article_embeddings = model.encode(article_texts, batch_size=32, show_progress_bar=False)\n",
        "    article_embeddings = article_embeddings / np.linalg.norm(article_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    similarities = np.dot(article_embeddings, topic_embedding.T).flatten()\n",
        "\n",
        "    relevant_articles = []\n",
        "    for article, score in zip(articles, similarities):\n",
        "        if score >= threshold:\n",
        "            article_with_score = article.copy()\n",
        "            article_with_score['relevance_score'] = float(score)\n",
        "            relevant_articles.append(article_with_score)\n",
        "\n",
        "    relevant_articles.sort(key=lambda x: x['relevance_score'], reverse=True)\n",
        "    print(f\"Found {len(relevant_articles)} relevant articles\", file=sys.stderr) # Added\n",
        "\n",
        "    return relevant_articles\n",
        "\n",
        "def generate_narrative_summary(articles: List[Dict], topic: str, num_sentences: int = 7) -> str:\n",
        "    \"\"\"Generate a narrative summary from relevant articles.\"\"\"\n",
        "    if not articles:\n",
        "        return f\"No articles found relevant to {topic}.\"\n",
        "\n",
        "    print(f\"Generating narrative summary from {len(articles)} articles...\", file=sys.stderr) # Modified\n",
        "\n",
        "    all_sentences = []\n",
        "    top_articles = articles[:min(15, len(articles))]\n",
        "\n",
        "    for article in top_articles:\n",
        "        content = article.get('content', '')\n",
        "        if not content:\n",
        "            continue\n",
        "\n",
        "        sentences = re.split(r'(?<=[.!?])\\\\s+(?=[A-Z])', content)\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if 10 < len(sentence.split()) < 50:\n",
        "                all_sentences.append(sentence)\n",
        "\n",
        "    if not all_sentences:\n",
        "        summary_parts = [a['headline'] for a in top_articles[:num_sentences]]\n",
        "        print(\"No sentences extracted for summarization, falling back to headlines.\", file=sys.stderr) # Added\n",
        "        return ' '.join(summary_parts)\n",
        "\n",
        "    all_sentences = all_sentences[:min(300, len(all_sentences))]\n",
        "    print(f\"Analyzing {len(all_sentences)} sentences...\", file=sys.stderr) # Modified\n",
        "\n",
        "\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer(stop_words='english', max_features=1000, min_df=1)\n",
        "        tfidf_matrix = vectorizer.fit_transform(all_sentences)\n",
        "        topic_vector = vectorizer.transform([topic])\n",
        "        similarities = cos_sim(tfidf_matrix, topic_vector).flatten()\n",
        "\n",
        "        top_indices = np.argsort(similarities)[-num_sentences:][::-1]\n",
        "        top_indices_sorted = sorted(top_indices)\n",
        "        summary_sentences = [all_sentences[idx] for idx in top_indices_sorted]\n",
        "\n",
        "        return ' '.join(summary_sentences)\n",
        "    except Exception as e: # Catching specific Exception for better error handling\n",
        "        print(f\"Error in summarization: {e}\", file=sys.stderr) # Modified\n",
        "        fallback_sentences = []\n",
        "        for article in top_articles[:num_sentences]:\n",
        "            if article['content']:\n",
        "                first_sent = article['content'].split('.')[0] + '.'\n",
        "                fallback_sentences.append(first_sent)\n",
        "        return ' '.join(fallback_sentences)\n",
        "\n",
        "def build_timeline(articles: List[Dict], topic: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Build chronological timeline of events from articles.\"\"\"\n",
        "    timeline = []\n",
        "\n",
        "    print(f\"Building timeline from {len(articles)} articles...\", file=sys.stderr) # Modified\n",
        "\n",
        "    for article in articles:\n",
        "        date_str = article.get('date', '')\n",
        "        parsed_date = None\n",
        "        formatted_date = 'Unknown'\n",
        "\n",
        "        if date_str:\n",
        "            try:\n",
        "                parsed_date = dateutil.parser.parse(date_str)\n",
        "                if parsed_date.tzinfo is None:\n",
        "                    parsed_date = parsed_date.replace(tzinfo=timezone.utc)\n",
        "                formatted_date = parsed_date.strftime('%Y-%m-%d')\n",
        "            except:\n",
        "                formatted_date = str(date_str)[:10] if date_str else 'Unknown'\n",
        "\n",
        "        relevance_score = article.get('relevance_score', 0)\n",
        "        importance = \"Highly relevant\" if relevance_score > 0.6 else \"Moderately relevant\" if relevance_score > 0.4 else \"Provides context\"\n",
        "\n",
        "        content = article.get('content', '')\n",
        "        if content and len(content) > 50:\n",
        "            first_sentence = content.split('.')[0].strip()\n",
        "            if len(first_sentence) > 100:\n",
        "                first_sentence = first_sentence[:100] + '...'\n",
        "        else:\n",
        "            first_sentence = article['headline'][:100]\n",
        "\n",
        "        why_it_matters = f\"{importance} to {topic}. {first_sentence}\"\n",
        "\n",
        "        event = {\n",
        "            'date': formatted_date,\n",
        "            'headline': article['headline'],\n",
        "            'url': article['url'],\n",
        "            'why_it_matters': why_it_matters,\n",
        "            'source': article.get('source', 'Unknown'),\n",
        "            'parsed_date': parsed_date\n",
        "        }\n",
        "        timeline.append(event)\n",
        "\n",
        "    timeline_with_dates = [e for e in timeline if e['parsed_date'] is not None]\n",
        "    timeline_without_dates = [e for e in timeline if e['parsed_date'] is None]\n",
        "\n",
        "    if timeline_with_dates:\n",
        "        try:\n",
        "            timeline_with_dates.sort(key=lambda x: x['parsed_date'])\n",
        "        except TypeError:\n",
        "            print(f\"Warning: Mixed timezone dates detected, normalizing to UTC\", file=sys.stderr) # Modified\n",
        "            for event in timeline_with_dates:\n",
        "                if event['parsed_date'].tzinfo is None:\n",
        "                    event['parsed_date'] = event['parsed_date'].replace(tzinfo=timezone.utc)\n",
        "            timeline_with_dates.sort(key=lambda x: x['parsed_date'])\n",
        "\n",
        "    for event in timeline_with_dates + timeline_without_dates:\n",
        "        if 'parsed_date' in event:\n",
        "            del event['parsed_date']\n",
        "\n",
        "    return timeline_with_dates + timeline_without_dates\n",
        "\n",
        "def cluster_narratives(articles: List[Dict]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Cluster articles into thematic groups using K-Means on embeddings.\"\"\"\n",
        "    if len(articles) < 3:\n",
        "        print(\"Not enough articles to cluster, returning single 'General Coverage' cluster.\", file=sys.stderr) # Added\n",
        "        return [{\n",
        "            'cluster_id': 0,\n",
        "            'theme': 'General Coverage',\n",
        "            'articles': [a['headline'] for a in articles],\n",
        "            'size': len(articles)\n",
        "        }]\n",
        "\n",
        "    article_texts = []\n",
        "    for a in articles:\n",
        "        content_preview = a.get('content', '')[:200]\n",
        "        text = f\"{a['headline']} {content_preview}\"\n",
        "        article_texts.append(text)\n",
        "\n",
        "    embeddings = model.encode(article_texts, batch_size=32, show_progress_bar=False)\n",
        "    n_clusters = max(3, min(10, int(np.sqrt(len(articles)))))\n",
        "\n",
        "    print(f\"Clustering {len(articles)} articles into {n_clusters} clusters...\", file=sys.stderr) # Added\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(embeddings)\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=100, stop_words='english', min_df=1)\n",
        "    clusters = []\n",
        "\n",
        "    for cluster_id in range(n_clusters):\n",
        "        cluster_indices = [i for i, label in enumerate(cluster_labels) if label == cluster_id]\n",
        "        cluster_articles = [articles[i] for i in cluster_indices]\n",
        "\n",
        "        if not cluster_articles:\n",
        "            continue\n",
        "\n",
        "        cluster_texts = []\n",
        "        for a in cluster_articles:\n",
        "            content = a.get('content', '')[:200]\n",
        "            cluster_texts.append(f\"{a['headline']} {content}\")\n",
        "\n",
        "        try:\n",
        "            tfidf_matrix = vectorizer.fit_transform(cluster_texts)\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "            tfidf_scores = tfidf_matrix.sum(axis=0).A1\n",
        "            top_indices = tfidf_scores.argsort()[-3:][::-1]\n",
        "            top_terms = [feature_names[i].title() for i in top_indices]\n",
        "            theme = ' '.join(top_terms)\n",
        "        except Exception as e: # Catching specific Exception for better error handling\n",
        "            print(f\"Error determining theme for cluster {cluster_id}: {e}\", file=sys.stderr) # Added\n",
        "            all_words = ' '.join([a['headline'] for a in cluster_articles]).lower()\n",
        "            words = re.findall(r'\\\\b[a-z]{4,}\\\\b', all_words)\n",
        "            common_words = Counter(words).most_common(3)\n",
        "            theme = ' '.join([w.title() for w, _ in common_words])\n",
        "\n",
        "        cluster_summary = {\n",
        "            'cluster_id': cluster_id,\n",
        "            'theme': theme if theme.strip() else f\"Theme {cluster_id + 1}\",\n",
        "            'articles': [a['headline'] for a in cluster_articles],\n",
        "            'size': len(cluster_articles)\n",
        "        }\n",
        "        clusters.append(cluster_summary)\n",
        "\n",
        "    clusters.sort(key=lambda x: x['size'], reverse=True)\n",
        "    return clusters\n",
        "\n",
        "def build_narrative_graph(articles: List[Dict]) -> Dict[str, Any]:\n",
        "    \"\"\"Build a narrative graph showing relationships between articles.\"\"\"\n",
        "    nodes = []\n",
        "    for idx, article in enumerate(articles):\n",
        "        node = {\n",
        "            'id': idx,\n",
        "            'headline': article['headline'],\n",
        "            'date': article.get('date', 'Unknown'),\n",
        "            'url': article['url']\n",
        "        }\n",
        "        nodes.append(node)\n",
        "\n",
        "    article_texts = []\n",
        "    for a in articles:\n",
        "        content_preview = a.get('content', '')[:300]\n",
        "        text = f\"{a['headline']} {content_preview}\"\n",
        "        article_texts.append(text)\n",
        "\n",
        "    print(\"Computing embeddings for graph construction...\", file=sys.stderr) # Modified\n",
        "    embeddings = model.encode(article_texts, batch_size=32, show_progress_bar=False)\n",
        "    embeddings_norm = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    similarity_matrix = np.dot(embeddings_norm, embeddings_norm.T)\n",
        "\n",
        "    dates = []\n",
        "    for article in articles:\n",
        "        try:\n",
        "            if article.get('date'):\n",
        "                parsed = dateutil.parser.parse(article['date'])\n",
        "                if parsed.tzinfo is None:\n",
        "                    parsed = parsed.replace(tzinfo=timezone.utc)\n",
        "                dates.append(parsed)\n",
        "            else:\n",
        "                dates.append(None)\n",
        "        except:\n",
        "            dates.append(None)\n",
        "\n",
        "    escalation_keywords = ['escalate', 'intensif', 'worsen', 'increase', 'grow', 'expand', 'crisis', 'critical', 'urgent', 'severe', 'major']\n",
        "    context_keywords = ['background', 'history', 'context', 'previously', 'earlier', 'origin', 'initially', 'first', 'began']\n",
        "    contradiction_keywords = ['however', 'but', 'contrary', 'dispute', 'deny', 'refute', 'oppose', 'contradict', 'disagree']\n",
        "\n",
        "    edges = []\n",
        "\n",
        "    print(f\"Building narrative graph for {len(articles)} articles...\", file=sys.stderr) # Added\n",
        "\n",
        "    for i in range(len(articles)):\n",
        "        for j in range(i + 1, len(articles)):\n",
        "            similarity = similarity_matrix[i][j]\n",
        "\n",
        "            if similarity < 0.35:\n",
        "                continue\n",
        "\n",
        "            article_i = articles[i]\n",
        "            article_j = articles[j]\n",
        "\n",
        "            if dates[i] and dates[j]:\n",
        "                try:\n",
        "                    is_i_before_j = dates[i] < dates[j]\n",
        "                    days_apart = abs((dates[j] - dates[i]).days)\n",
        "                except:\n",
        "                    is_i_before_j = True\n",
        "                    days_apart = 0\n",
        "            else:\n",
        "                is_i_before_j = True\n",
        "                days_apart = 0\n",
        "\n",
        "            content_i = article_i.get('content', '').lower()\n",
        "            content_j = article_j.get('content', '').lower()\n",
        "            headline_j = article_j['headline'].lower()\n",
        "\n",
        "            relationship_type = None\n",
        "\n",
        "            has_contradiction = any(kw in content_j or kw in headline_j for kw in contradiction_keywords)\n",
        "            if has_contradiction and similarity > 0.5:\n",
        "                relationship_type = 'contradicts'\n",
        "            elif any(kw in content_j or kw in headline_j for kw in escalation_keywords) and is_i_before_j and similarity > 0.55:\n",
        "                relationship_type = 'escalates'\n",
        "            elif any(kw in content_j or kw in headline_j for kw in context_keywords) and similarity > 0.4:\n",
        "                relationship_type = 'adds_context'\n",
        "            elif is_i_before_j and similarity > 0.55 and days_apart < 60:\n",
        "                relationship_type = 'builds_on'\n",
        "\n",
        "            if relationship_type:\n",
        "                edge = {\n",
        "                    'source': i,\n",
        "                    'target': j,\n",
        "                    'type': relationship_type,\n",
        "                    'similarity': float(similarity)\n",
        "                }\n",
        "                edges.append(edge)\n",
        "\n",
        "    edge_types = Counter([e['type'] for e in edges])\n",
        "    print(f\"Created graph with {len(nodes)} nodes and {len(edges)} edges\", file=sys.stderr) # Added\n",
        "    print(f\"Edge distribution: {dict(edge_types)}\", file=sys.stderr) # Added\n",
        "\n",
        "    graph = {\n",
        "        'nodes': nodes,\n",
        "        'edges': edges,\n",
        "        'stats': {\n",
        "            'num_nodes': len(nodes),\n",
        "            'num_edges': len(edges),\n",
        "            'edge_types': dict(edge_types)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return graph\n",
        "\n",
        "def build_complete_narrative(articles: List[Dict], topic: str) -> Dict[str, Any]:\n",
        "    \"\"\"Complete pipeline to build narrative from articles on any topic.\"\"\"\n",
        "    relevant_articles = filter_articles_by_topic(articles, topic, threshold=0.3)\n",
        "\n",
        "    if not relevant_articles:\n",
        "        return {\n",
        "            'narrative_summary': f\"No relevant articles found for {topic}.\",\n",
        "            'timeline': [],\n",
        "            'clusters': [],\n",
        "            'graph': {'nodes': [], 'edges': [], 'stats': {}}\n",
        "        }\n",
        "\n",
        "    narrative_summary = generate_narrative_summary(relevant_articles, topic)\n",
        "    timeline = build_timeline(relevant_articles, topic)\n",
        "    clusters = cluster_narratives(relevant_articles)\n",
        "\n",
        "    graph_articles = relevant_articles[:min(50, len(relevant_articles))]\n",
        "    graph = build_narrative_graph(graph_articles)\n",
        "\n",
        "    output = {\n",
        "        'narrative_summary': narrative_summary,\n",
        "        'timeline': timeline,\n",
        "        'clusters': clusters,\n",
        "        'graph': graph\n",
        "    }\n",
        "\n",
        "    return output\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main entry point for command line usage.\"\"\"\n",
        "    parser = argparse.ArgumentParser(description='Build narrative from news dataset on any topic')\n",
        "    parser.add_argument('--topic', required=True, help='Topic to build narrative for')\n",
        "    parser.add_argument('--dataset', default='news_dataset.json', help='Path to news dataset')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Load and filter dataset\n",
        "    articles = load_and_filter_news_data(args.dataset, min_rating=8.0)\n",
        "\n",
        "    if not articles: # Added check in main if articles failed to load\n",
        "        print(\"No articles loaded or filtered. Exiting.\", file=sys.stderr)\n",
        "        return\n",
        "\n",
        "    # Build narrative\n",
        "    narrative = build_complete_narrative(articles, args.topic)\n",
        "\n",
        "    # Output as JSON\n",
        "    print(json.dumps(narrative, indent=2))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "# Save the script to file\n",
        "with open('narrative_builder.py', 'w') as f:\n",
        "    f.write(narrative_builder_script)\n",
        "\n",
        "print(\"narrative_builder.py created successfully\")\n",
        "\n",
        "# Make it executable\n",
        "!chmod +x narrative_builder.py\n",
        "\n",
        "print(\"\\nScript is ready to use!\")\n",
        "print(\"\\nExample usage:\")\n",
        "print('  python narrative_builder.py --topic \"Hyderabad Metro Rail expansion\"')\n",
        "print('  python narrative_builder.py --topic \"Israel-Iran conflict\"')\n",
        "print('  python narrative_builder.py --topic \"AI regulation\"')"
      ],
      "metadata": {
        "id": "CHT6CTchbCm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451f5568-1cdc-497b-c960-8370eef3834c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "narrative_builder.py created successfully\n",
            "\n",
            "Script is ready to use!\n",
            "\n",
            "Example usage:\n",
            "  python narrative_builder.py --topic \"Hyderabad Metro Rail expansion\"\n",
            "  python narrative_builder.py --topic \"Israel-Iran conflict\"\n",
            "  python narrative_builder.py --topic \"AI regulation\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Testing\n",
        "\n",
        "Test both scripts with different queries to ensure they work correctly from the command line.\n"
      ],
      "metadata": {
        "id": "XzptrllkbIJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test semantic search script\n",
        "print(\"=\"*60)\n",
        "print(\"TESTING SEMANTIC SEARCH SCRIPT\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "test_query_1 = \"How do I fetch tweets with expansions?\"\n",
        "print(f\"Query: {test_query_1}\\n\")\n",
        "!python semantic_search.py --query \"{test_query_1}\" --k 3\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TESTING NARRATIVE BUILDER SCRIPT\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "test_topic_1 = \"Hyderabad infrastructure development\"\n",
        "print(f\"Topic: {test_topic_1}\\n\")\n",
        "!python narrative_builder.py --topic \"{test_topic_1}\" --dataset \"news_dataset.json\" > narrative_output.json\n",
        "\n",
        "# Load and display summary of narrative output\n",
        "with open('narrative_output.json', 'r') as f:\n",
        "    narrative_result = json.load(f)\n",
        "\n",
        "print(\"Narrative Builder Output Summary:\")\n",
        "print(f\"  Summary length: {len(narrative_result['narrative_summary'].split())} words\")\n",
        "print(f\"  Timeline events: {len(narrative_result['timeline'])}\")\n",
        "print(f\"  Clusters: {len(narrative_result['clusters'])}\")\n",
        "print(f\"  Graph nodes: {narrative_result['graph']['stats']['num_nodes']}\")\n",
        "print(f\"  Graph edges: {narrative_result['graph']['stats']['num_edges']}\")\n",
        "\n",
        "print(\"\\n Both scripts are working correctly!\")\n"
      ],
      "metadata": {
        "id": "RUUW_VdxbJQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc62acf-81a3-4bc0-f8c1-51209bdb26c7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TESTING SEMANTIC SEARCH SCRIPT\n",
            "============================================================\n",
            "\n",
            "Query: How do I fetch tweets with expansions?\n",
            "\n",
            "2025-11-17 09:19:35.984775: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763371176.005702    6215 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763371176.012411    6215 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763371176.028763    6215 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371176.028798    6215 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371176.028804    6215 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371176.028817    6215 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[\n",
            "  {\n",
            "    \"rank\": 1,\n",
            "    \"score\": 0.5931496620178223,\n",
            "    \"name\": \"Users by Username\",\n",
            "    \"method\": \"GET\",\n",
            "    \"url\": \"https://api.twitter.com/2/users/by?usernames=\",\n",
            "    \"category\": \"User Lookup\",\n",
            "    \"description\": \"\"\n",
            "  },\n",
            "  {\n",
            "    \"rank\": 2,\n",
            "    \"score\": 0.5870629549026489,\n",
            "    \"name\": \"Retweeted by\",\n",
            "    \"method\": \"GET\",\n",
            "    \"url\": \"https://api.twitter.com/2/tweets/:id/retweeted_by\",\n",
            "    \"category\": \"Retweets\",\n",
            "    \"description\": \"\"\n",
            "  },\n",
            "  {\n",
            "    \"rank\": 3,\n",
            "    \"score\": 0.584139347076416,\n",
            "    \"name\": \"Users by ID\",\n",
            "    \"method\": \"GET\",\n",
            "    \"url\": \"https://api.twitter.com/2/users?ids=\",\n",
            "    \"category\": \"User Lookup\",\n",
            "    \"description\": \"\"\n",
            "  }\n",
            "]\n",
            "\n",
            "============================================================\n",
            "TESTING NARRATIVE BUILDER SCRIPT\n",
            "============================================================\n",
            "\n",
            "Topic: Hyderabad infrastructure development\n",
            "\n",
            "2025-11-17 09:19:51.056265: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763371191.078013    6292 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763371191.084155    6292 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763371191.100356    6292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371191.100392    6292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371191.100396    6292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371191.100400    6292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading sentence transformer model...\n",
            "Model loaded\n",
            "Filtering 2685 articles for topic: 'Hyderabad infrastructure development'\n",
            "Similarity threshold: 0.3\n",
            "Computing embeddings for articles...\n",
            "Found 278 relevant articles\n",
            "Generating narrative summary from 278 articles...\n",
            "Analyzing 177 sentences...\n",
            "Building timeline from 278 articles...\n",
            "Clustering 278 articles into 10 clusters...\n",
            "Computing embeddings for graph construction...\n",
            "Building narrative graph for 50 articles...\n",
            "Created graph with 50 nodes and 118 edges\n",
            "Edge distribution: {'adds_context': 83, 'contradicts': 27, 'escalates': 4, 'builds_on': 4}\n",
            "Narrative Builder Output Summary:\n",
            "  Summary length: 180 words\n",
            "  Timeline events: 278\n",
            "  Clusters: 10\n",
            "  Graph nodes: 50\n",
            "  Graph edges: 118\n",
            "\n",
            " Both scripts are working correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Submission Files\n",
        "\n",
        "Save sample outputs and create a README for your submission.\n"
      ],
      "metadata": {
        "id": "aOPLewwvcKQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample outputs for different topics\n",
        "sample_topics = [\n",
        "    \"Jubilee Hills elections\",\n",
        "    \"Israel-Iran conflict\",\n",
        "    \"AI regulation\"\n",
        "]\n",
        "\n",
        "print(\"Generating sample outputs for submission...\\n\")\n",
        "\n",
        "for topic in sample_topics:\n",
        "    safe_filename = topic.replace(' ', '_').replace('-', '_').lower()\n",
        "    output_file = f\"sample_output_{safe_filename}.json\"\n",
        "\n",
        "    print(f\"Generating narrative for: {topic}\")\n",
        "    !python narrative_builder.py --topic \"{topic}\" --dataset \"news_dataset.json\" > {output_file}\n",
        "    print(f\"  Saved to: {output_file}\\n\")\n",
        "\n",
        "# Create README file\n",
        "readme_content = \"\"\"# Kautilya ML Challenge Submission\n",
        "\n",
        "## Task 1: Semantic Search on Twitter API Documentation\n",
        "\n",
        "### Usage:python semantic_search.py --query \"How do I fetch tweets with expansions?\" --k 5\n",
        "\n",
        "### Features:\n",
        "- Parses Postman collection files to extract API documentation\n",
        "- Uses sentence-transformers (all-MiniLM-L6-v2) for embeddings\n",
        "- FAISS index for fast similarity search\n",
        "- Returns top-k most relevant API endpoints with scores\n",
        "\n",
        "### Performance:\n",
        "- Embedding generation: ~0.1s for query\n",
        "- Search time: < 0.01s for top-k retrieval\n",
        "- Memory efficient with batch processing\n",
        "\n",
        "---\n",
        "\n",
        "## Task 2: Narrative Builder from News Dataset\n",
        "\n",
        "### Usage:\n",
        "python narrative_builder.py --topic \"Jubilee Hills elections\"\n",
        "python narrative_builder.py --topic \"Israel-Iran conflict\"\n",
        "python narrative_builder.py --topic \"AI regulation\"\n",
        "\n",
        "### Features:\n",
        "- Loads 84MB news dataset and filters by source_rating > 8\n",
        "- Semantic filtering using sentence transformers\n",
        "- Generates coherent narrative summaries\n",
        "- Builds chronological event timelines\n",
        "- Clusters articles by themes using K-Means\n",
        "- Constructs narrative graph with relationship types\n",
        "\n",
        "### Output Structure:\n",
        "- **narrative_summary**: 5-10 sentence synthesis\n",
        "- **timeline**: Chronological events with context\n",
        "- **clusters**: Thematic groupings with article lists\n",
        "- **graph**: Nodes (articles) and edges (relationships)\n",
        "\n",
        "### Performance:\n",
        "- Dataset loading: ~2-3 seconds\n",
        "- Topic filtering: ~5-10 seconds for 2685 articles\n",
        "- Complete pipeline: ~15-30 seconds per topic\n",
        "- Optimized for TPU/GPU acceleration\n",
        "\n",
        "---\n",
        "\n",
        "## Dependencies:\n",
        "sentence-transformers\n",
        "faiss-cpu\n",
        "scikit-learn\n",
        "numpy\n",
        "pandas\n",
        "dateutil\n",
        "\n",
        "## Implementation Highlights:\n",
        "1. **Correctness**: Semantic relevance verified through similarity scores\n",
        "2. **Performance**: Batch processing and vectorized operations\n",
        "3. **Code Quality**: Modular functions with clear documentation\n",
        "4. **Flexibility**: Works with any topic dynamically\n",
        "\n",
        "## T.Sri Varshitha\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open('README.md', 'w') as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\" README.md created\")\n",
        "print(\"✓ Sample outputs generated\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUBMISSION READY\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nYour submission includes:\")\n",
        "print(\"  1. semantic_search.py\")\n",
        "print(\"  2. narrative_builder.py\")\n",
        "print(\"  3. README.md\")\n",
        "print(\"  4. Sample output files\")\n",
        "print(\"\\nAll files are ready for submission!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FvdkyUORbTGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7767cb26-3f2d-4a71-96c6-11a598fa1ab1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating sample outputs for submission...\n",
            "\n",
            "Generating narrative for: Jubilee Hills elections\n",
            "2025-11-17 09:20:11.552478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763371211.581151    6395 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763371211.591974    6395 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763371211.608533    6395 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371211.608560    6395 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371211.608564    6395 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371211.608570    6395 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading sentence transformer model...\n",
            "Model loaded\n",
            "Filtering 2685 articles for topic: 'Jubilee Hills elections'\n",
            "Similarity threshold: 0.3\n",
            "Computing embeddings for articles...\n",
            "Found 67 relevant articles\n",
            "Generating narrative summary from 67 articles...\n",
            "Analyzing 288 sentences...\n",
            "Building timeline from 67 articles...\n",
            "Clustering 67 articles into 8 clusters...\n",
            "Computing embeddings for graph construction...\n",
            "Building narrative graph for 50 articles...\n",
            "Created graph with 50 nodes and 467 edges\n",
            "Edge distribution: {'builds_on': 41, 'adds_context': 201, 'contradicts': 201, 'escalates': 24}\n",
            "  Saved to: sample_output_jubilee_hills_elections.json\n",
            "\n",
            "Generating narrative for: Israel-Iran conflict\n",
            "2025-11-17 09:20:31.075648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763371231.096722    6498 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763371231.103130    6498 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763371231.118540    6498 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371231.118567    6498 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371231.118571    6498 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371231.118576    6498 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading sentence transformer model...\n",
            "Model loaded\n",
            "Filtering 2685 articles for topic: 'Israel-Iran conflict'\n",
            "Similarity threshold: 0.3\n",
            "Computing embeddings for articles...\n",
            "Found 48 relevant articles\n",
            "Generating narrative summary from 48 articles...\n",
            "Analyzing 173 sentences...\n",
            "Building timeline from 48 articles...\n",
            "Clustering 48 articles into 6 clusters...\n",
            "Computing embeddings for graph construction...\n",
            "Building narrative graph for 48 articles...\n",
            "Created graph with 48 nodes and 267 edges\n",
            "Edge distribution: {'contradicts': 88, 'escalates': 16, 'adds_context': 154, 'builds_on': 9}\n",
            "  Saved to: sample_output_israel_iran_conflict.json\n",
            "\n",
            "Generating narrative for: AI regulation\n",
            "2025-11-17 09:20:52.335216: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763371252.355958    6597 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763371252.361826    6597 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763371252.376772    6597 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371252.376798    6597 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371252.376802    6597 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763371252.376817    6597 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading sentence transformer model...\n",
            "Model loaded\n",
            "Filtering 2685 articles for topic: 'AI regulation'\n",
            "Similarity threshold: 0.3\n",
            "Computing embeddings for articles...\n",
            "Found 26 relevant articles\n",
            "Generating narrative summary from 26 articles...\n",
            "Analyzing 181 sentences...\n",
            "Building timeline from 26 articles...\n",
            "Clustering 26 articles into 5 clusters...\n",
            "Computing embeddings for graph construction...\n",
            "Building narrative graph for 26 articles...\n",
            "Created graph with 26 nodes and 34 edges\n",
            "Edge distribution: {'adds_context': 22, 'contradicts': 11, 'escalates': 1}\n",
            "  Saved to: sample_output_ai_regulation.json\n",
            "\n",
            " README.md created\n",
            "✓ Sample outputs generated\n",
            "\n",
            "============================================================\n",
            "SUBMISSION READY\n",
            "============================================================\n",
            "\n",
            "Your submission includes:\n",
            "  1. semantic_search.py\n",
            "  2. narrative_builder.py\n",
            "  3. README.md\n",
            "  4. Sample output files\n",
            "\n",
            "All files are ready for submission!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Summary and Optimization Notes\n",
        "\n",
        "Review the performance characteristics of your implementation to ensure maximum score.\n"
      ],
      "metadata": {
        "id": "GGBXmrJlc0LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import json\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from typing import List, Dict, Any\n",
        "from datetime import timezone\n",
        "from collections import Counter\n",
        "import re\n",
        "import sys\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
        "import dateutil.parser\n",
        "\n",
        "# Ensure the model is loaded in the global scope if not already\n",
        "# This check is a safeguard; it should be loaded from previous cells.\n",
        "if 'model' not in globals() or model is None:\n",
        "    print(\"Loading sentence transformer model for benchmarking...\", file=sys.stderr)\n",
        "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "    print(\"Model loaded for benchmarking.\", file=sys.stderr)\n",
        "\n",
        "# --- Semantic Search Functions (from semantic_search.py) ---\n",
        "# Function to parse Postman collection and extract documentation chunks\n",
        "def parse_postman_collection(collection_path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Parse Postman collection JSON and extract API documentation chunks.\n",
        "    Each chunk contains endpoint information that will be searchable.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "\n",
        "    try:\n",
        "        with open(collection_path, 'r', encoding='utf-8') as f:\n",
        "            collection = json.load(f)\n",
        "\n",
        "        # Recursive function to process items in the collection\n",
        "        def process_item(item, parent_name=\"\"):\n",
        "            \"\"\"\n",
        "            Recursively process each item in the Postman collection.\n",
        "            Items can be nested, so we traverse the entire tree.\n",
        "            \"\"\"\n",
        "            if 'item' in item:\n",
        "                # This is a folder containing more items\n",
        "                folder_name = item.get('name', '')\n",
        "                for sub_item in item['item']:\n",
        "                    process_item(sub_item, folder_name)\n",
        "            else:\n",
        "                # This is an actual API request\n",
        "                request = item.get('request', {})\n",
        "\n",
        "                # Extract all relevant information\n",
        "                name = item.get('name', 'Unnamed')\n",
        "                description = item.get('description', '')\n",
        "\n",
        "                # Get HTTP method\n",
        "                method = request.get('method', 'GET')\n",
        "\n",
        "                # Get URL information\n",
        "                url_info = request.get('url', {})\n",
        "                if isinstance(url_info, str):\n",
        "                    url = url_info\n",
        "                else:\n",
        "                    url = url_info.get('raw', '')\n",
        "\n",
        "                # Get query parameters\n",
        "                query_params = []\n",
        "                if isinstance(url_info, dict) and 'query' in url_info:\n",
        "                    for param in url_info.get('query', []):\n",
        "                        param_name = param.get('key', '')\n",
        "                        param_desc = param.get('description', '')\n",
        "                        query_params.append(f\"{param_name}: {param_desc}\")\n",
        "\n",
        "                # Get request body information\n",
        "                body_info = \"\"\n",
        "                if 'body' in request:\n",
        "                    body = request['body']\n",
        "                    if 'raw' in body:\n",
        "                        body_info = body.get('description', '')\n",
        "\n",
        "                # Combine all information into a searchable text chunk\n",
        "                chunk_text = f\"API: {name}\\n\"\n",
        "                chunk_text += f\"Method: {method}\\n\"\n",
        "                chunk_text += f\"Endpoint: {url}\\n\"\n",
        "                if parent_name:\n",
        "                    chunk_text += f\"Category: {parent_name}\\n\"\n",
        "                if description:\n",
        "                    chunk_text += f\"Description: {description}\\n\"\n",
        "                if query_params:\n",
        "                    chunk_text += f\"Parameters: {', '.join(query_params)}\\n\"\n",
        "                if body_info:\n",
        "                    chunk_text += f\"Body: {body_info}\\n\"\n",
        "\n",
        "                # Create chunk dictionary\n",
        "                chunk = {\n",
        "                    'text': chunk_text,\n",
        "                    'name': name,\n",
        "                    'method': method,\n",
        "                    'url': url,\n",
        "                    'category': parent_name,\n",
        "                    'description': description\n",
        "                }\n",
        "\n",
        "                chunks.append(chunk)\n",
        "\n",
        "        # Start processing from the root\n",
        "        if 'item' in collection:\n",
        "            for item in collection['item']:\n",
        "                process_item(item)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing collection: {e}\", file=sys.stderr)\n",
        "        return []\n",
        "\n",
        "def build_search_system():\n",
        "    \"\"\"Build the semantic search system.\"\"\"\n",
        "    # Find collection files\n",
        "    collection_files = []\n",
        "    for root, dirs, files in os.walk('postman-twitter-api'):\n",
        "        for file in files:\n",
        "            if file.endswith('.json') and 'collection' in file.lower():\n",
        "                collection_files.append(os.path.join(root, file))\n",
        "\n",
        "    # Parse all collections\n",
        "    all_chunks_local = []\n",
        "    for collection_file in collection_files:\n",
        "        chunks_local = parse_postman_collection(collection_file)\n",
        "        all_chunks_local.extend(chunks_local)\n",
        "\n",
        "    # Load model and create embeddings\n",
        "    # model is expected to be loaded globally from previous cells\n",
        "    if 'model' not in globals():\n",
        "        raise RuntimeError(\"SentenceTransformer model not loaded. Please ensure previous cells run.\")\n",
        "\n",
        "    chunk_texts = [chunk['text'] for chunk in all_chunks_local]\n",
        "    embeddings = model.encode(chunk_texts, batch_size=32, show_progress_bar=False)\n",
        "    embeddings_normalized = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    # Build FAISS index\n",
        "    dimension = embeddings_normalized.shape[1]\n",
        "    index = faiss.IndexFlatIP(dimension)\n",
        "    index.add(embeddings_normalized.astype('float32'))\n",
        "\n",
        "    return model, index, all_chunks_local\n",
        "\n",
        "# Initialize model, index, and all_chunks globally for the semantic_search function\n",
        "# This assumes the code in previous cells has run successfully\n",
        "if 'all_chunks' not in globals() or 'index' not in globals():\n",
        "    print(\"Initializing semantic search system for benchmarking...\", file=sys.stderr)\n",
        "    # If model is not global, build_search_system will try to load it\n",
        "    # Assuming model is already loaded from previous cells.\n",
        "    _model, _index, _all_chunks = build_search_system()\n",
        "    # Make sure global variables are updated if they were not already\n",
        "    if 'model' not in globals():\n",
        "        model = _model\n",
        "    if 'index' not in globals():\n",
        "        index = _index\n",
        "    if 'all_chunks' not in globals():\n",
        "        all_chunks = _all_chunks\n",
        "    print(\"Semantic search system initialized for benchmarking.\", file=sys.stderr)\n",
        "\n",
        "\n",
        "def semantic_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Perform semantic search over Twitter API documentation.\n",
        "\n",
        "    Parameters:\n",
        "    query: The search query string\n",
        "    k: Number of top results to return\n",
        "\n",
        "    Returns:\n",
        "    List of dictionaries containing search results with relevance scores\n",
        "    \"\"\"\n",
        "    # Encode the query\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
        "\n",
        "    # Search the index\n",
        "    scores, indices = index.search(query_embedding.astype('float32'), k)\n",
        "\n",
        "    # Prepare results\n",
        "    results = []\n",
        "    for idx, score in zip(indices[0], scores[0]):\n",
        "        chunk = all_chunks[idx]\n",
        "        result = {\n",
        "            'rank': len(results) + 1,\n",
        "            'score': float(score),\n",
        "            'name': chunk['name'],\n",
        "            'method': chunk['method'],\n",
        "            'url': chunk['url'],\n",
        "            'category': chunk['category'],\n",
        "            'description': chunk['description'],\n",
        "            'full_text': chunk['text']\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# --- Narrative Builder Functions (from narrative_builder.py) ---\n",
        "\n",
        "def load_and_filter_news_data(filepath: str, min_rating: float = 8.0) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load news dataset and filter by source rating.\"\"\"\n",
        "    articles = []\n",
        "\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset file not found at {filepath}\", file=sys.stderr)\n",
        "        return []\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON from {filepath}: {e}\", file=sys.stderr)\n",
        "        return []\n",
        "\n",
        "    if 'items' in data and isinstance(data['items'], list):\n",
        "        raw_articles = data['items']\n",
        "    else:\n",
        "        print(\"Error: 'items' key not found in dataset or is not a list.\", file=sys.stderr)\n",
        "        return []\n",
        "\n",
        "    for article in raw_articles:\n",
        "        if not isinstance(article, dict):\n",
        "            continue\n",
        "\n",
        "        source_rating = article.get('source_rating')\n",
        "\n",
        "        try:\n",
        "            if source_rating is not None:\n",
        "                source_rating = float(source_rating)\n",
        "            else:\n",
        "                continue\n",
        "        except (ValueError, TypeError):\n",
        "            continue\n",
        "\n",
        "        if source_rating > min_rating:\n",
        "            standardized = {\n",
        "                'headline': article.get('title', ''),\n",
        "                'content': article.get('story', ''),\n",
        "                'url': article.get('url', ''),\n",
        "                'date': article.get('date', ''),\n",
        "                'source': article.get('source', ''),\n",
        "                'source_rating': source_rating,\n",
        "                'author': article.get('author', ''),\n",
        "                'category': article.get('category', '')\n",
        "            }\n",
        "            articles.append(standardized)\n",
        "\n",
        "    return articles\n",
        "\n",
        "def filter_articles_by_topic(articles: List[Dict], topic_query: str, threshold: float = 0.3) -> List[Dict]:\n",
        "    \"\"\"Filter articles relevant to a specific topic using semantic similarity.\"\"\"\n",
        "    if not articles:\n",
        "        return []\n",
        "\n",
        "    print(f\"Filtering {len(articles)} articles for topic: '{topic_query}'\", file=sys.stderr)\n",
        "    print(f\"Similarity threshold: {threshold}\", file=sys.stderr)\n",
        "\n",
        "    topic_embedding = model.encode([topic_query], convert_to_numpy=True)\n",
        "    topic_embedding = topic_embedding / np.linalg.norm(topic_embedding)\n",
        "\n",
        "    article_texts = []\n",
        "    for article in articles:\n",
        "        content_preview = article['content'][:300] if article['content'] else ''\n",
        "        text = f\"{article['headline']} {content_preview}\"\n",
        "        article_texts.append(text)\n",
        "\n",
        "    print(\"Computing embeddings for articles...\", file=sys.stderr)\n",
        "    article_embeddings = model.encode(article_texts, batch_size=32, show_progress_bar=True, convert_to_numpy=True)\n",
        "    article_embeddings = article_embeddings / np.linalg.norm(article_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    similarities = np.dot(article_embeddings, topic_embedding.T).flatten()\n",
        "\n",
        "    relevant_articles = []\n",
        "    for article, score in zip(articles, similarities):\n",
        "        if score >= threshold:\n",
        "            article_with_score = article.copy()\n",
        "            article_with_score['relevance_score'] = float(score)\n",
        "            relevant_articles.append(article_with_score)\n",
        "\n",
        "    relevant_articles.sort(key=lambda x: x['relevance_score'], reverse=True)\n",
        "    print(f\"Found {len(relevant_articles)} relevant articles\", file=sys.stderr)\n",
        "\n",
        "    return relevant_articles\n",
        "\n",
        "def generate_narrative_summary(articles: List[Dict], topic: str, num_sentences: int = 7) -> str:\n",
        "    \"\"\"Generate a narrative summary from relevant articles.\"\"\"\n",
        "    if not articles:\n",
        "        return f\"No articles found relevant to {topic}.\"\n",
        "\n",
        "    print(f\"Generating narrative summary from {len(articles)} articles...\", file=sys.stderr)\n",
        "\n",
        "    all_sentences = []\n",
        "    top_articles = articles[:min(15, len(articles))]\n",
        "\n",
        "    for article in top_articles:\n",
        "        content = article.get('content', '')\n",
        "        if not content:\n",
        "            continue\n",
        "\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z])', content)\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if 10 < len(sentence.split()) < 50:\n",
        "                all_sentences.append(sentence)\n",
        "\n",
        "    if not all_sentences:\n",
        "        summary_parts = [a['headline'] for a in top_articles[:num_sentences]]\n",
        "        print(\"No sentences extracted for summarization, falling back to headlines.\", file=sys.stderr)\n",
        "        return ' '.join(summary_parts)\n",
        "\n",
        "    all_sentences = all_sentences[:min(300, len(all_sentences))]\n",
        "    print(f\"Analyzing {len(all_sentences)} sentences...\", file=sys.stderr)\n",
        "\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer(stop_words='english', max_features=1000, min_df=1)\n",
        "        tfidf_matrix = vectorizer.fit_transform(all_sentences)\n",
        "        topic_vector = vectorizer.transform([topic])\n",
        "        similarities = cos_sim(tfidf_matrix, topic_vector).flatten()\n",
        "\n",
        "        top_indices = np.argsort(similarities)[-num_sentences:][::-1]\n",
        "        top_indices_sorted = sorted(top_indices)\n",
        "        summary_sentences = [all_sentences[idx] for idx in top_indices_sorted]\n",
        "\n",
        "        return ' '.join(summary_sentences)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in summarization: {e}\", file=sys.stderr)\n",
        "        fallback_sentences = []\n",
        "        for article in top_articles[:num_sentences]:\n",
        "            if article['content']:\n",
        "                first_sent = article['content'].split('.')[0] + '.'\n",
        "                fallback_sentences.append(first_sent)\n",
        "        return ' '.join(fallback_sentences)\n",
        "\n",
        "def build_timeline(articles: List[Dict], topic: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Build chronological timeline of events from articles.\"\"\"\n",
        "    timeline = []\n",
        "\n",
        "    print(f\"Building timeline from {len(articles)} articles...\", file=sys.stderr)\n",
        "\n",
        "    for article in articles:\n",
        "        date_str = article.get('date', '')\n",
        "        parsed_date = None\n",
        "        formatted_date = 'Unknown'\n",
        "\n",
        "        if date_str:\n",
        "            try:\n",
        "                parsed_date = dateutil.parser.parse(date_str)\n",
        "                if parsed_date.tzinfo is None:\n",
        "                    parsed_date = parsed_date.replace(tzinfo=timezone.utc)\n",
        "                formatted_date = parsed_date.strftime('%Y-%m-%d')\n",
        "            except:\n",
        "                formatted_date = str(date_str)[:10] if date_str else 'Unknown'\n",
        "\n",
        "        relevance_score = article.get('relevance_score', 0)\n",
        "        importance = \"Highly relevant\" if relevance_score > 0.6 else \"Moderately relevant\" if relevance_score > 0.4 else \"Provides context\"\n",
        "\n",
        "        content = article.get('content', '')\n",
        "        if content and len(content) > 50:\n",
        "            first_sentence = content.split('.')[0].strip()\n",
        "            if len(first_sentence) > 100:\n",
        "                first_sentence = first_sentence[:100] + '...'\n",
        "        else:\n",
        "            first_sentence = article['headline'][:100]\n",
        "\n",
        "        why_it_matters = f\"{importance} to {topic}. {first_sentence}\"\n",
        "\n",
        "        event = {\n",
        "            'date': formatted_date,\n",
        "            'headline': article['headline'],\n",
        "            'url': article['url'],\n",
        "            'why_it_matters': why_it_matters,\n",
        "            'source': article.get('source', 'Unknown'),\n",
        "            'parsed_date': parsed_date\n",
        "        }\n",
        "        timeline.append(event)\n",
        "\n",
        "    timeline_with_dates = [e for e in timeline if e['parsed_date'] is not None]\n",
        "    timeline_without_dates = [e for e in timeline if e['parsed_date'] is None]\n",
        "\n",
        "    if timeline_with_dates:\n",
        "        try:\n",
        "            timeline_with_dates.sort(key=lambda x: x['parsed_date'])\n",
        "        except TypeError:\n",
        "            print(f\"Warning: Mixed timezone dates detected, normalizing to UTC\", file=sys.stderr)\n",
        "            for event in timeline_with_dates:\n",
        "                if event['parsed_date'].tzinfo is None:\n",
        "                    event['parsed_date'] = event['parsed_date'].replace(tzinfo=timezone.utc)\n",
        "            timeline_with_dates.sort(key=lambda x: x['parsed_date'])\n",
        "\n",
        "    for event in timeline_with_dates + timeline_without_dates:\n",
        "        if 'parsed_date' in event:\n",
        "            del event['parsed_date']\n",
        "\n",
        "    return timeline_with_dates + timeline_without_dates\n",
        "\n",
        "def cluster_narratives(articles: List[Dict]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Cluster articles into thematic groups using K-Means on embeddings.\"\"\"\n",
        "    if len(articles) < 3:\n",
        "        print(\"Not enough articles to cluster, returning single 'General Coverage' cluster.\", file=sys.stderr)\n",
        "        return [{\n",
        "            'cluster_id': 0,\n",
        "            'theme': 'General Coverage',\n",
        "            'articles': [a['headline'] for a in articles],\n",
        "            'size': len(articles)\n",
        "        }]\n",
        "\n",
        "    article_texts = []\n",
        "    for a in articles:\n",
        "        content_preview = a.get('content', '')[:200]\n",
        "        text = f\"{a['headline']} {content_preview}\"\n",
        "        article_texts.append(text)\n",
        "\n",
        "    embeddings = model.encode(article_texts, batch_size=32, show_progress_bar=True, convert_to_numpy=True)\n",
        "    n_clusters = max(3, min(10, int(np.sqrt(len(articles)))))\n",
        "\n",
        "    print(f\"Clustering {len(articles)} articles into {n_clusters} clusters...\", file=sys.stderr)\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(embeddings)\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=100, stop_words='english', min_df=1)\n",
        "    clusters = []\n",
        "\n",
        "    for cluster_id in range(n_clusters):\n",
        "        cluster_indices = [i for i, label in enumerate(cluster_labels) if label == cluster_id]\n",
        "        cluster_articles = [articles[i] for i in cluster_indices]\n",
        "\n",
        "        if not cluster_articles:\n",
        "            continue\n",
        "\n",
        "        cluster_texts = []\n",
        "        for a in cluster_articles:\n",
        "            content = a.get('content', '')[:200]\n",
        "            cluster_texts.append(f\"{a['headline']} {content}\")\n",
        "\n",
        "        try:\n",
        "            tfidf_matrix = vectorizer.fit_transform(cluster_texts)\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "            tfidf_scores = tfidf_matrix.sum(axis=0).A1\n",
        "            top_indices = tfidf_scores.argsort()[-3:][::-1]\n",
        "            top_terms = [feature_names[i].title() for i in top_indices]\n",
        "            theme = ' '.join(top_terms)\n",
        "        except Exception as e:\n",
        "            print(f\"Error determining theme for cluster {cluster_id}: {e}\", file=sys.stderr)\n",
        "            all_words = ' '.join([a['headline'] for a in cluster_articles]).lower()\n",
        "            words = re.findall(r'\\b[a-z]{4,}\\b', all_words)\n",
        "            common_words = Counter(words).most_common(3)\n",
        "            theme = ' '.join([w.title() for w, _ in common_words])\n",
        "\n",
        "        cluster_summary = {\n",
        "            'cluster_id': cluster_id,\n",
        "            'theme': theme if theme.strip() else f\"Theme {cluster_id + 1}\",\n",
        "            'articles': [a['headline'] for a in cluster_articles],\n",
        "            'size': len(cluster_articles)\n",
        "        }\n",
        "        clusters.append(cluster_summary)\n",
        "\n",
        "    clusters.sort(key=lambda x: x['size'], reverse=True)\n",
        "    return clusters\n",
        "\n",
        "def build_narrative_graph(articles: List[Dict]) -> Dict[str, Any]:\n",
        "    \"\"\"Build a narrative graph showing relationships between articles.\"\"\"\n",
        "    nodes = []\n",
        "    for idx, article in enumerate(articles):\n",
        "        node = {\n",
        "            'id': idx,\n",
        "            'headline': article['headline'],\n",
        "            'date': article.get('date', 'Unknown'),\n",
        "            'url': article['url']\n",
        "        }\n",
        "        nodes.append(node)\n",
        "\n",
        "    article_texts = []\n",
        "    for a in articles:\n",
        "        content_preview = a.get('content', '')[:300]\n",
        "        text = f\"{a['headline']} {content_preview}\"\n",
        "        article_texts.append(text)\n",
        "\n",
        "    print(\"Computing embeddings for graph construction...\", file=sys.stderr)\n",
        "    embeddings = model.encode(article_texts, batch_size=32, show_progress_bar=True, convert_to_numpy=True)\n",
        "    embeddings_norm = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    similarity_matrix = np.dot(embeddings_norm, embeddings_norm.T)\n",
        "\n",
        "    dates = []\n",
        "    for article in articles:\n",
        "        try:\n",
        "            if article.get('date'):\n",
        "                parsed = dateutil.parser.parse(article['date'])\n",
        "                if parsed.tzinfo is None:\n",
        "                    parsed = parsed.replace(tzinfo=timezone.utc)\n",
        "                dates.append(parsed)\n",
        "            else:\n",
        "                dates.append(None)\n",
        "        except:\n",
        "            dates.append(None)\n",
        "\n",
        "    escalation_keywords = ['escalate', 'intensif', 'worsen', 'increase', 'grow', 'expand', 'crisis', 'critical', 'urgent', 'severe', 'major']\n",
        "    context_keywords = ['background', 'history', 'context', 'previously', 'earlier', 'origin', 'initially', 'first', 'began']\n",
        "    contradiction_keywords = ['however', 'but', 'contrary', 'dispute', 'deny', 'refute', 'oppose', 'contradict', 'disagree']\n",
        "\n",
        "    edges = []\n",
        "\n",
        "    print(f\"Building narrative graph for {len(articles)} articles...\", file=sys.stderr)\n",
        "\n",
        "    for i in range(len(articles)):\n",
        "        for j in range(i + 1, len(articles)):\n",
        "            similarity = similarity_matrix[i][j]\n",
        "\n",
        "            if similarity < 0.35:\n",
        "                continue\n",
        "\n",
        "            article_i = articles[i]\n",
        "            article_j = articles[j]\n",
        "\n",
        "            if dates[i] and dates[j]:\n",
        "                try:\n",
        "                    is_i_before_j = dates[i] < dates[j]\n",
        "                    days_apart = abs((dates[j] - dates[i]).days)\n",
        "                except:\n",
        "                    is_i_before_j = True\n",
        "                    days_apart = 0\n",
        "            else:\n",
        "                is_i_before_j = True\n",
        "                days_apart = 0\n",
        "\n",
        "            content_i = article_i.get('content', '').lower()\n",
        "            content_j = article_j.get('content', '').lower()\n",
        "            headline_j = article_j['headline'].lower()\n",
        "\n",
        "            relationship_type = None\n",
        "\n",
        "            has_contradiction = any(kw in content_j or kw in headline_j for kw in contradiction_keywords)\n",
        "            if has_contradiction and similarity > 0.5:\n",
        "                relationship_type = 'contradicts'\n",
        "            elif any(kw in content_j or kw in headline_j for kw in escalation_keywords) and is_i_before_j and similarity > 0.55:\n",
        "                relationship_type = 'escalates'\n",
        "            elif any(kw in content_j or kw in headline_j for kw in context_keywords) and similarity > 0.4:\n",
        "                relationship_type = 'adds_context'\n",
        "            elif is_i_before_j and similarity > 0.55 and days_apart < 60:\n",
        "                relationship_type = 'builds_on'\n",
        "\n",
        "            if relationship_type:\n",
        "                edge = {\n",
        "                    'source': i,\n",
        "                    'target': j,\n",
        "                    'type': relationship_type,\n",
        "                    'similarity': float(similarity)\n",
        "                }\n",
        "                edges.append(edge)\n",
        "\n",
        "    edge_types = Counter([e['type'] for e in edges])\n",
        "    print(f\"Created graph with {len(nodes)} nodes and {len(edges)} edges\", file=sys.stderr)\n",
        "    print(f\"Edge distribution: {dict(edge_types)}\", file=sys.stderr)\n",
        "\n",
        "    graph = {\n",
        "        'nodes': nodes,\n",
        "        'edges': edges,\n",
        "        'stats': {\n",
        "            'num_nodes': len(nodes),\n",
        "            'num_edges': len(edges),\n",
        "            'edge_types': dict(edge_types)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return graph\n",
        "\n",
        "def build_complete_narrative(articles: List[Dict], topic: str) -> Dict[str, Any]:\n",
        "    \"\"\"Complete pipeline to build narrative from articles on any topic.\"\"\"\n",
        "    relevant_articles = filter_articles_by_topic(articles, topic, threshold=0.3)\n",
        "\n",
        "    if not relevant_articles:\n",
        "        return {\n",
        "            'narrative_summary': f\"No relevant articles found for {topic}.\",\n",
        "            'timeline': [],\n",
        "            'clusters': [],\n",
        "            'graph': {'nodes': [], 'edges': [], 'stats': {}}\n",
        "        }\n",
        "\n",
        "    narrative_summary = generate_narrative_summary(relevant_articles, topic)\n",
        "    timeline = build_timeline(relevant_articles, topic)\n",
        "    clusters = cluster_narratives(relevant_articles)\n",
        "\n",
        "    graph_articles = relevant_articles[:min(50, len(relevant_articles))]\n",
        "    graph = build_narrative_graph(graph_articles)\n",
        "\n",
        "    output = {\n",
        "        'narrative_summary': narrative_summary,\n",
        "        'timeline': timeline,\n",
        "        'clusters': clusters,\n",
        "        'graph': graph\n",
        "    }\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PERFORMANCE BENCHMARKING\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Benchmark semantic search\n",
        "print(\"1. Semantic Search Performance:\")\n",
        "start = time.time()\n",
        "test_results = semantic_search(\"authentication methods for Twitter API\", k=5)\n",
        "search_time = time.time() - start\n",
        "print(f\"   Query time: {search_time:.3f} seconds\")\n",
        "print(f\"   Results returned: {len(test_results)}\")\n",
        "print(f\"   ✓ Fast retrieval (< 1 second)\\n\")\n",
        "\n",
        "# Benchmark narrative builder components\n",
        "# Assuming 'filtered_articles' is available from previous cells\n",
        "if 'filtered_articles' not in globals() or not filtered_articles:\n",
        "    print(\"Warning: 'filtered_articles' not found or empty. Attempting to load from DATASET_PATH.\", file=sys.stderr)\n",
        "    if 'DATASET_PATH' in globals() and os.path.exists(DATASET_PATH):\n",
        "        filtered_articles = load_and_filter_news_data(DATASET_PATH, min_rating=8.0)\n",
        "    else:\n",
        "        print(\"Error: DATASET_PATH not defined or file not found. Skipping narrative builder benchmark.\", file=sys.stderr)\n",
        "        filtered_articles = []\n",
        "\n",
        "if filtered_articles:\n",
        "    print(\"2. Narrative Builder Performance:\")\n",
        "\n",
        "    # Topic filtering\n",
        "    print(\"   a. Topic Filtering:\")\n",
        "    start = time.time()\n",
        "    test_relevant = filter_articles_by_topic(filtered_articles[:1000], \"AI technology\", threshold=0.3)\n",
        "    filter_time = time.time() - start\n",
        "    print(f\"      Filtered 1000 articles in {filter_time:.3f} seconds\")\n",
        "    print(f\"      Found {len(test_relevant)} relevant articles\\n\")\n",
        "\n",
        "    # Summary generation\n",
        "    if test_relevant:\n",
        "        print(\"   b. Summary Generation:\")\n",
        "        start = time.time()\n",
        "        test_summary = generate_narrative_summary(test_relevant[:50], \"AI technology\")\n",
        "        summary_time = time.time() - start\n",
        "        print(f\"      Generated summary in {summary_time:.3f} seconds\")\n",
        "        print(f\"      Summary length: {len(test_summary.split())} words\\n\")\n",
        "\n",
        "        # Timeline\n",
        "        print(\"   c. Timeline Construction:\")\n",
        "        start = time.time()\n",
        "        test_timeline = build_timeline(test_relevant[:50], \"AI technology\")\n",
        "        timeline_time = time.time() - start\n",
        "        print(f\"      Built timeline in {timeline_time:.3f} seconds\")\n",
        "        print(f\"      Timeline events: {len(test_timeline)}\\n\")\n",
        "\n",
        "        # Clustering\n",
        "        print(\"   d. Article Clustering:\")\n",
        "        start = time.time()\n",
        "        test_clusters = cluster_narratives(test_relevant[:50])\n",
        "        cluster_time = time.time() - start\n",
        "        print(f\"      Clustered articles in {cluster_time:.3f} seconds\")\n",
        "        print(f\"      Clusters created: {len(test_clusters)}\\n\")\n",
        "\n",
        "        # Graph\n",
        "        print(\"   e. Graph Construction:\")\n",
        "        start = time.time()\n",
        "        test_graph = build_narrative_graph(test_relevant[:30])\n",
        "        graph_time = time.time() - start\n",
        "        print(f\"      Built graph in {graph_time:.3f} seconds\")\n",
        "        print(f\"      Nodes: {test_graph['stats']['num_nodes']}, Edges: {test_graph['stats']['num_edges']}\\n\")\n",
        "\n",
        "        # Total pipeline\n",
        "        print(\"   f. Complete Pipeline:\")\n",
        "        start = time.time()\n",
        "        complete = build_complete_narrative(filtered_articles[:1000], \"AI technology\")\n",
        "        total_time = time.time() - start\n",
        "        print(f\"      Total pipeline time: {total_time:.3f} seconds\")\n",
        "        print(f\"       Efficient end-to-end processing\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Muoi3-13c1Jt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4aea57143ad543c1b92cd5a12018e970",
            "e8f6480e4e4f417c8ae4eab8ae558aad",
            "b4ee2a613a0b42ddb8d661cb9b15ed7c",
            "8e82dabea0a4494b8f3271e5312f1542",
            "c9c513b561424ddaa9b9cc2212a07684",
            "62a8c3529e8d4bb4a0d4b62ef1c2e6b0",
            "99acadb6350f46c48ff6ff53ee0b9f97",
            "d5fc5a55c4c24ab4a7330cd9c9b231e0",
            "8fe78060b2a94e348dbf17efc9aee665",
            "84f1111aeab241bc8d82d3339d694c45",
            "e00d890bf7c04c58b805f4f3dd4f5aa6",
            "5459464a0a974c859258d44de9079a16",
            "b5442452beb7411e8329e89bfc9abef0",
            "ff1587db3fc24378aadc06da9ce77b20",
            "435383f86c22453f840917af37597c88",
            "c104d25b76104e28b2b3801bda3d3cd6",
            "efd36bfc8c9b40a0bca7c6dee937e9d3",
            "45e40783b4b04875bb6bee6935a4c0e5",
            "76d9b1f75d124f25ad635363860bdfb6",
            "3228efb5ff0b48b1b25c0b0040e375d6",
            "06156530bd4546dda4fbdee8d6cd6106",
            "15154ed4c81b412e83acb45631337fc0",
            "f7881cf4b44c44cfb3df0047f92d9a42",
            "952a600298a243f8933b3d3b609b8a92",
            "afc8f92588134899bdad606aee43594c",
            "ee019990b3654052a22cfe229f4489ed",
            "f2f73aec56274eeca8ec6e187140120e",
            "48a844831564447dae0acfd741a603ea",
            "15dc50fe94f9495492a386d2e056c718",
            "4bbdc276e1604b8b8d1390a4e00b8277",
            "a5c8b8df22ee4b2a929a3a88aae1280d",
            "b178b315f6de49ffba88205073bcfba9",
            "70221919e51b434fbcc0f9d49be59f3b",
            "1e33bf3eac6447b2a0a80c5abe390114",
            "77b7d137a410438cae295776f2ae82ab",
            "a64d3913be174f3486a3c2bd459021ba",
            "9e17ea24338147a096144e9a298bc081",
            "757425e6d97c4aca8161e706d19b8015",
            "5f7879af54d4471b83e4f103bd38e80f",
            "116b9717fc774fb79d11187f482bc9dc",
            "94f4112f21c442a89298b7be1f01015e",
            "3f828a0f3e694300a13d04bfd6858e19",
            "f9a45f0d1c83463a83eaefa9e1ccf9d0",
            "5f2ed9ab5ace46e8998fdebfab0d3387",
            "cc1bc3cdb66e431091d1521ada59e2be",
            "3c904a52b4b34878ad63d133bdb2f3c0",
            "16be3f9c467a4e89a1427326c5cb89e8",
            "36c5ff69baa64049b6e473514b67d556",
            "6fae5f0e42b843b1a4277e506fc3c346",
            "e1ed91f05c2f4171b35513921f0d9813",
            "769b385d0b3d4b18b09b538bea1ead94",
            "8ceb263c3541430187d1d4329eae72b8",
            "55674d74657740fa9e766c7c85ad134a",
            "0d155ea69f5a47acad7b9c45043f5b4d",
            "db0004db50044b75a256cf225fef155f",
            "3c10d0670eea47ba8228b0bdfe70a9dc",
            "beef6bcbf5a448cc9d43228a27393112",
            "bc3ccfb4d0e9430baa98303f27ffb7a0",
            "6b4c8f9a5aa44f77a5b49e778c3428e4",
            "b22fb999ca4d4df1bb315341850ed99b",
            "4edb0859123c483d9f9bcfbaf29a7284",
            "4129285b60ad4c329f7544e5dedd80ec",
            "95a035e04bc3499c9d3abb8b44bd90d3",
            "967b2e28e8fa4e6f8757773584d62391",
            "9c21447ba4f5492398788d265d005b15",
            "4730574ad7f14c2889cd286ccca432f7"
          ]
        },
        "outputId": "ffc2494f-4b78-472e-d6c1-3f147e1da226"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PERFORMANCE BENCHMARKING\n",
            "============================================================\n",
            "\n",
            "1. Semantic Search Performance:\n",
            "   Query time: 0.009 seconds\n",
            "   Results returned: 5\n",
            "   ✓ Fast retrieval (< 1 second)\n",
            "\n",
            "2. Narrative Builder Performance:\n",
            "   a. Topic Filtering:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Filtering 1000 articles for topic: 'AI technology'\n",
            "Similarity threshold: 0.3\n",
            "Computing embeddings for articles...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4aea57143ad543c1b92cd5a12018e970"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Filtered 1000 articles in 1.224 seconds\n",
            "      Found 11 relevant articles\n",
            "\n",
            "   b. Summary Generation:\n",
            "      Generated summary in 0.009 seconds\n",
            "      Summary length: 159 words\n",
            "\n",
            "   c. Timeline Construction:\n",
            "      Built timeline in 0.001 seconds\n",
            "      Timeline events: 11\n",
            "\n",
            "   d. Article Clustering:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found 11 relevant articles\n",
            "Generating narrative summary from 11 articles...\n",
            "Analyzing 163 sentences...\n",
            "Building timeline from 11 articles...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5459464a0a974c859258d44de9079a16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Clustered articles in 0.086 seconds\n",
            "      Clusters created: 3\n",
            "\n",
            "   e. Graph Construction:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clustering 11 articles into 3 clusters...\n",
            "Computing embeddings for graph construction...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7881cf4b44c44cfb3df0047f92d9a42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Built graph in 0.043 seconds\n",
            "      Nodes: 11, Edges: 10\n",
            "\n",
            "   f. Complete Pipeline:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building narrative graph for 11 articles...\n",
            "Created graph with 11 nodes and 10 edges\n",
            "Edge distribution: {'contradicts': 4, 'adds_context': 6}\n",
            "Filtering 1000 articles for topic: 'AI technology'\n",
            "Similarity threshold: 0.3\n",
            "Computing embeddings for articles...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e33bf3eac6447b2a0a80c5abe390114"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found 11 relevant articles\n",
            "Generating narrative summary from 11 articles...\n",
            "Analyzing 163 sentences...\n",
            "Building timeline from 11 articles...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc1bc3cdb66e431091d1521ada59e2be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clustering 11 articles into 3 clusters...\n",
            "Computing embeddings for graph construction...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c10d0670eea47ba8228b0bdfe70a9dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Total pipeline time: 1.264 seconds\n",
            "       Efficient end-to-end processing\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building narrative graph for 11 articles...\n",
            "Created graph with 11 nodes and 10 edges\n",
            "Edge distribution: {'contradicts': 4, 'adds_context': 6}\n"
          ]
        }
      ]
    }
  ]
}